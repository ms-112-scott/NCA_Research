{
 "cells": [
  {
   "cell_type": "raw",
   "id": "537ef3eb",
   "metadata": {},
   "source": [
    "def frame_data(frame):\n",
    "    frame_depth = calcu_frame_depth(frame)  #HW 深度圖\n",
    "    frame_seg = calcu_frame_seg(frame)  #HW seg圖\n",
    "\n",
    "    single_depth = depth_single_value(frame_depth)  #float 單一數值\n",
    "    single_seg = seg_single_value(frame_seg)  #float 單一數值\n",
    "\n",
    "    single_change = calcu_frame_change(frame)  #float 單一數值\n",
    "\n",
    "    frame_data = [single_depth, single_seg, single_change, gpsx, gpsy, gpsz, anglex, angley, anglez] #9個特徵值\n",
    "    return frame_data\n",
    "\n",
    "\n",
    "\n",
    "for video in videos:\n",
    "    video_data= []\n",
    "    for frame in video:\n",
    "        frame_data = frame_data(frame)  #9個特徵值\n",
    "        video_data.append(frame_data) #  2d array (Time, Vector)\n",
    "\n",
    "    save_video_data(video_data) \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62051c0f",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1d1a271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import mmcv\n",
    "from mmseg.apis import init_model, inference_model\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f35e83b",
   "metadata": {},
   "source": [
    "# global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afc1a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_folder = \"C:/Users/yutse/OneDrive/桌面/cg/dataset_video/video\"  # 影片資料夾\n",
    "output_folder = \"C:/Users/yutse/OneDrive/桌面/cg/image_score_test/output\"  # 輸出總資料夾\n",
    "output_npz = \"C:/Users/yutse/OneDrive/桌面/cg/dataset_video/all_videos_data.npz\"\n",
    "\n",
    "# mmseg model config / checkpoint --- 請修改為你本機路徑\n",
    "mmseg_config = '../mmSeg_trained_models/pspnet_r50-d8_4xb2-40k_cityscapes-512x1024.py'\n",
    "mmseg_checkpoint = '../mmSeg_trained_models/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'\n",
    "\n",
    "# MiDaS model 名稱（torch.hub）\n",
    "midas_model_name = \"DPT_Hybrid\"  # 使用 DPT_Hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d8e27a",
   "metadata": {},
   "source": [
    "# setup midas model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beae9d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用裝置: cuda\n",
      "載入 MiDaS 模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\yutse/.cache\\torch\\hub\\intel-isl_MiDaS_master\n",
      "Using cache found in C:\\Users\\yutse/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "midas_model_name = \"DPT_Hybrid\"  # 使用 DPT_Hybrid\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# ------------------- 設備設定 -------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"使用裝置: {device}\")\n",
    "\n",
    "# ------------------- 載入 MiDaS -------------------\n",
    "print(\"載入 MiDaS 模型...\")\n",
    "try:\n",
    "    midas = torch.hub.load(\"intel-isl/MiDaS\", midas_model_name).to(device).eval()\n",
    "    midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "    # DPT 用 dpt_transform，其它模型 transform 名稱可能不同\n",
    "    if hasattr(midas_transforms, \"dpt_transform\"):\n",
    "        midas_transform = midas_transforms.dpt_transform\n",
    "    else:\n",
    "        midas_transform = midas_transforms.default_transform\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"載入 MiDaS 失敗: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48af4333",
   "metadata": {},
   "source": [
    "## setup seg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f68f872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "載入 mmseg 模型...\n",
      "Loads checkpoint by local backend from path: ../mmSeg_trained_models/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth\n"
     ]
    }
   ],
   "source": [
    "# ------------------- 載入 mmseg -------------------\n",
    "print(\"載入 mmseg 模型...\")\n",
    "if not os.path.exists(mmseg_config) or not os.path.exists(mmseg_checkpoint):\n",
    "    raise FileNotFoundError(\"請確認 mmseg 的 config 與 checkpoint 路徑是否正確。\")\n",
    "MMSEG_DEVICE = f\"cuda:0\" if device.startswith(\"cuda\") else \"cpu\"\n",
    "SEG_MODEL = init_model(mmseg_config, mmseg_checkpoint, device=device)\n",
    "\n",
    "# 從模型 meta 取得類別與調色盤\n",
    "CLASSES = SEG_MODEL.dataset_meta.get('classes', None)\n",
    "PALETTE = SEG_MODEL.dataset_meta.get('palette', None)\n",
    "if CLASSES is None:\n",
    "    raise RuntimeError(\"無法從 mmseg model 取得 classes metadata。\")\n",
    "\n",
    "# 人造 vs 自然 類別集合（根據你之前定義，可自行擴充或修改）\n",
    "HUMAN_MADE = {'road','sidewalk','building','wall','fence','pole',\n",
    "            'traffic light','traffic sign','car','truck','bus','train',\n",
    "            'motorcycle','bicycle'}\n",
    "# ----------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36719249",
   "metadata": {},
   "source": [
    "# funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b60595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_video_frames(folder_path, n_frames=1):\n",
    "    \"\"\"\n",
    "    掃描 folder_path 底下所有 .mp4 檔案，逐幀回傳。\n",
    "    \n",
    "    Yield:\n",
    "        (video_path, frame_index, frame_bgr)\n",
    "    \"\"\"\n",
    "    folder_path = os.path.abspath(folder_path)\n",
    "    video_list = [\n",
    "        os.path.join(folder_path, f)\n",
    "        for f in os.listdir(folder_path)\n",
    "        if f.lower().endswith(\".mp4\")\n",
    "    ]\n",
    "\n",
    "    for video_path in sorted(video_list):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"[Warning] 無法開啟影片: {video_path}\")\n",
    "            continue\n",
    "\n",
    "        frame_idx = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            yield video_path, frame_idx, frame\n",
    "            frame_idx += n_frames\n",
    "\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20368c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bgr(frame):\n",
    "    \"\"\"\n",
    "    將輸入影像安全轉換成 BGR (H, W, 3, uint8)。\n",
    "    支援以下輸入：\n",
    "      - BGR (直接回傳)\n",
    "      - RGB\n",
    "      - RGBA / BGRA\n",
    "      - Gray (H, W)\n",
    "      - float 或 0~1 資料（自動 clip 與轉 uint8）\n",
    "    \"\"\"\n",
    "    if frame is None:\n",
    "        raise ValueError(\"to_bgr() 收到 None\")\n",
    "\n",
    "    arr = np.array(frame)\n",
    "\n",
    "    # 將 float 範圍調整成 uint8\n",
    "    if arr.dtype != np.uint8:\n",
    "        arr = np.clip(arr * 255 if arr.max() <= 1.0 else arr, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # 灰階 -> BGR\n",
    "    if arr.ndim == 2:\n",
    "        return cv2.cvtColor(arr, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    if arr.ndim != 3 or arr.shape[2] not in (3, 4):\n",
    "        raise ValueError(f\"無法處理的影像形狀: {arr.shape}\")\n",
    "\n",
    "    h, w, c = arr.shape\n",
    "\n",
    "    # BGR\n",
    "    if c == 3:\n",
    "        # 判斷是否可能是 RGB\n",
    "        # (簡單推論，無法完全保證，但足以應對一般使用)\n",
    "        if np.mean(arr[...,2]) > np.mean(arr[...,0]):  \n",
    "            return cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)\n",
    "        else:\n",
    "            return arr.copy()\n",
    "\n",
    "    # RGBA/BGRA -> BGR\n",
    "    if c == 4:\n",
    "        # 偵測是否 RGBA\n",
    "        if np.mean(arr[...,2]) > np.mean(arr[...,0]):\n",
    "            return cv2.cvtColor(arr, cv2.COLOR_RGBA2BGR)\n",
    "        else:\n",
    "            return cv2.cvtColor(arr, cv2.COLOR_BGRA2BGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73534ffa",
   "metadata": {},
   "source": [
    "## depth funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ba47aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- depth helper ----------\n",
    "def compute_depth_map(rgb_frame, midas_model, transform_fn, device, out_size=None):\n",
    "    \"\"\"\n",
    "    rgb_frame: HxWx3 uint8 (RGB)\n",
    "    回傳 float32 2D depth map（未標準化的相對深度）。\n",
    "    \"\"\"\n",
    "    input_tensor = transform_fn(rgb_frame).to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = midas_model(input_tensor)\n",
    "        # 處理輸出維度差異\n",
    "        if pred.ndim == 4:\n",
    "            pred = pred.squeeze(0).squeeze(0)\n",
    "        elif pred.ndim == 3:\n",
    "            pred = pred.squeeze(0)\n",
    "        pred_resized = torch.nn.functional.interpolate(\n",
    "            pred.unsqueeze(0).unsqueeze(0),\n",
    "            size=rgb_frame.shape[:2], mode=\"bicubic\", align_corners=False\n",
    "        ).squeeze().cpu().numpy()\n",
    "    if out_size is not None:\n",
    "        H_out, W_out = out_size\n",
    "        if (pred_resized.shape[0], pred_resized.shape[1]) != (H_out, W_out):\n",
    "            pred_resized = cv2.resize(pred_resized, (W_out, H_out), interpolation=cv2.INTER_CUBIC)\n",
    "    return pred_resized.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8c1252",
   "metadata": {},
   "source": [
    "## seg funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f25849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(*images, titles=None):\n",
    "    \"\"\"\n",
    "    比較多張影像，並可自訂標題。\n",
    "    \n",
    "    Args:\n",
    "        *images: 任意數量的影像，BGR 格式 (mmcv.imread 讀取)\n",
    "        titles: 可選，list of str，對應每張影像的標題\n",
    "                如果未提供，預設依序為 ['原圖', '語意分割', '後處理', ...]\n",
    "    \"\"\"\n",
    "    n = len(images)\n",
    "    if titles is None:\n",
    "        # 預設標題，依照影像數量生成\n",
    "        default_titles = ['原圖', '語意分割', '後處理']\n",
    "        titles = default_titles[:n] + [f'圖像{i+1}' for i in range(n - len(default_titles))]\n",
    "    \n",
    "    plt.figure(figsize=(5*n, 5))\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        plt.subplot(1, n, i+1)\n",
    "        # 如果是 BGR，轉 RGB\n",
    "        if isinstance(img, np.ndarray) and img.shape[-1] == 3:\n",
    "            plt.imshow(mmcv.bgr2rgb(img))\n",
    "        else:\n",
    "            plt.imshow(img)\n",
    "        plt.title(titles[i])\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3aef386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_to_instance_masks(seg_map: np.ndarray, target_class: int, min_area=50):\n",
    "    \"\"\"\n",
    "    從語意分割結果中提取某一類別的 instance mask\n",
    "    seg_map: HxW (int) 語意標籤圖\n",
    "    target_class: 要提取的類別 id\n",
    "    min_area: 過濾小面積雜訊\n",
    "    return: instance_masks (list of binary mask), labeled_map (HxW, 每個像素標記對應的 instance id)\n",
    "    \"\"\"\n",
    "    binary_mask = (seg_map == target_class).astype(np.uint8) * 255\n",
    "    \n",
    "    # 找 connected components\n",
    "    num_labels, labels = cv2.connectedComponents(binary_mask)\n",
    "    \n",
    "    instance_masks = []\n",
    "    instance_id_map = np.zeros_like(seg_map, dtype=np.int32)\n",
    "    \n",
    "    instance_id = 1\n",
    "    for label in range(1, num_labels):  # 0 是背景\n",
    "        mask = (labels == label).astype(np.uint8)\n",
    "        if cv2.countNonZero(mask) >= min_area:\n",
    "            instance_masks.append(mask)\n",
    "            instance_id_map[mask == 1] = instance_id\n",
    "            instance_id += 1\n",
    "\n",
    "    return instance_masks, instance_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "987da088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_seg_frame(frame: np.ndarray, model=None):\n",
    "    \"\"\"\n",
    "    只做 mmseg 推論（不視覺化）。\n",
    "    輸入:\n",
    "      frame : np.uint8 HxWx3 (BGR)\n",
    "    回傳:\n",
    "      frame (原 BGR)\n",
    "      seg_map : np.int64 HxW (mmseg class index)\n",
    "      seg_classified : np.int64 HxW  (0: nature, 1: human-made)\n",
    "      (human_ratio, nature_ratio)\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        try:\n",
    "            model = SEG_MODEL\n",
    "        except NameError:\n",
    "            raise ValueError(\"未提供 model，且全域 SEG_MODEL 未定義。\")\n",
    "\n",
    "    tmp_path = None\n",
    "    try:\n",
    "        # 寫入暫存檔\n",
    "        fd, tmp_path = tempfile.mkstemp(suffix=\".jpg\")\n",
    "        os.close(fd)\n",
    "        mmcv.imwrite(frame, tmp_path)\n",
    "\n",
    "        # mmseg inference\n",
    "        result = inference_model(model, tmp_path)\n",
    "        sd = result[0] if isinstance(result, (list, tuple)) else result\n",
    "\n",
    "        # 取得 seg_map\n",
    "        if hasattr(sd, \"pred_sem_seg\"):\n",
    "            seg_map = sd.pred_sem_seg\n",
    "        elif isinstance(sd, dict) and \"pred_sem_seg\" in sd:\n",
    "            seg_map = sd[\"pred_sem_seg\"]\n",
    "        elif isinstance(sd, np.ndarray):\n",
    "            seg_map = sd\n",
    "        else:\n",
    "            raise ValueError(\"無法從 mmseg 結果取得 pred_sem_seg。\")\n",
    "\n",
    "        if hasattr(seg_map, \"data\"):\n",
    "            seg_map = seg_map.data\n",
    "        if isinstance(seg_map, torch.Tensor):\n",
    "            seg_map = seg_map.squeeze().cpu().numpy()\n",
    "\n",
    "        # 若為 (C,H,W) 機率地圖\n",
    "        if getattr(seg_map, \"ndim\", 0) == 3:\n",
    "            seg_map = seg_map.argmax(axis=0)\n",
    "\n",
    "        seg_map = seg_map.astype(np.int64)\n",
    "\n",
    "        # 重新分類: 0 = nature，1 = human-made\n",
    "        seg_classified = np.zeros_like(seg_map, dtype=np.int64)\n",
    "\n",
    "        # label_type[i] = 1 if human-made else 0\n",
    "        label_type = np.array([1 if cls in HUMAN_MADE else 0 for cls in CLASSES],\n",
    "                              dtype=np.int8)\n",
    "\n",
    "        # 填入 seg_classified\n",
    "        for i, cls in enumerate(CLASSES):\n",
    "            mask = (seg_map == i)\n",
    "            seg_classified[mask] = 1 if cls in HUMAN_MADE else 0\n",
    "\n",
    "        # 計算比例\n",
    "        total_pixels = seg_map.size if seg_map.size > 0 else 1\n",
    "        human_pixels = int(np.sum(label_type[seg_map] == 1))\n",
    "        nature_pixels = int(np.sum(label_type[seg_map] == 0))\n",
    "\n",
    "        human_ratio = human_pixels / (total_pixels + 1e-8)\n",
    "        nature_ratio = nature_pixels / (total_pixels + 1e-8)\n",
    "\n",
    "        return frame, seg_map, seg_classified, (human_ratio, nature_ratio)\n",
    "\n",
    "    finally:\n",
    "        if tmp_path is not None and os.path.exists(tmp_path):\n",
    "            try:\n",
    "                os.remove(tmp_path)\n",
    "            except Exception:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4288740",
   "metadata": {},
   "source": [
    "## img change rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "749f0a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全域變數，用於保存前一幀\n",
    "_prev_frame = None\n",
    "\n",
    "def compute_img_change(frame: np.ndarray):\n",
    "    \"\"\"\n",
    "    計算當前 frame 相對於上一幀的影像變化指標。\n",
    "    \n",
    "    輸入:\n",
    "        frame : np.uint8 HxWx3 (BGR)\n",
    "    \n",
    "    回傳:\n",
    "        change_metrics : dict，包含：\n",
    "            'L1'      : float, L1 pixel 差異平均\n",
    "            '1-SSIM'  : float, 1-SSIM\n",
    "            'FlowMag' : float, 光流 magnitude mean\n",
    "        若無上一幀，返回 None\n",
    "    注意:\n",
    "        - 此函式會維持內部前一幀狀態。\n",
    "        - 若第一次呼叫，返回 None。\n",
    "    \"\"\"\n",
    "    global _prev_frame\n",
    "    if _prev_frame is None:\n",
    "        _prev_frame = frame.copy()\n",
    "        return {\"L1\": 0, \"1-SSIM\": 0, \"FlowMag\": 0}\n",
    "\n",
    "    # ----- L1 差異 -----\n",
    "    l1_val = np.mean(np.abs(_prev_frame.astype(np.float32) - frame.astype(np.float32)))\n",
    "\n",
    "    # ----- 1-SSIM -----\n",
    "    prev_gray = cv2.cvtColor(_prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    curr_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    ssim_val = ssim(prev_gray, curr_gray)\n",
    "    one_minus_ssim = 1.0 - ssim_val\n",
    "\n",
    "    # ----- 光流 FlowMag -----\n",
    "    prev_gray_f = prev_gray.astype(np.float32)\n",
    "    curr_gray_f = curr_gray.astype(np.float32)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray_f, curr_gray_f,\n",
    "                                        None,\n",
    "                                        pyr_scale=0.5, levels=3, winsize=15,\n",
    "                                        iterations=3, poly_n=5, poly_sigma=1.2, flags=0)\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    flow_mag_mean = mag.mean()\n",
    "\n",
    "    # 更新上一幀\n",
    "    _prev_frame = frame.copy()\n",
    "\n",
    "    return {\"L1\": l1_val, \"1-SSIM\": one_minus_ssim, \"FlowMag\": flow_mag_mean}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017040e7",
   "metadata": {},
   "source": [
    "## viz funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6c79186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_hw(arr, title=None):\n",
    "    \"\"\"\n",
    "    可視化 H×W numpy array。\n",
    "    arr: np.ndarray, shape=(H, W)\n",
    "    \"\"\"\n",
    "    if arr.ndim != 2:\n",
    "        raise ValueError(\"Input 必須是 H×W 的 2D numpy array\")\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(arr, cmap=\"gray\")\n",
    "    plt.title(title if title else \"Visualization\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c28e59dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def viz_seg_results(img_rgb, seg_map, seg_classified=None, classes=CLASSES, show_compare=True, processed_color_map=None):\n",
    "    \"\"\"\n",
    "    負責視覺化語意分割結果（不再執行推論）。\n",
    "    參數:\n",
    "      img_rgb: HxWx3 (uint8) - 原圖\n",
    "      seg_map: HxW int - 原始 class index map (同 process_seg_frame 回傳)\n",
    "      seg_classified: HxW int (1 or 2) - 可選，若 None 將根據 classes 與 HUMAN_MADE 自行生成\n",
    "      classes: list of class names 對應 seg_map 的 index\n",
    "      show_compare: bool - 是否呼叫 compare_images 顯示原圖 / raw seg / processed seg\n",
    "      processed_color_map: optional dict / list mapping class index -> RGB triplet\n",
    "    行為:\n",
    "      - 產生三張圖：原圖、原始語意分割上色、後處理（二值：人造/自然 上色）\n",
    "      - 若有 compare_images helper，則以該 helper 顯示\n",
    "      - 回傳 (seg_rgb, seg_processed_rgb) 以便後續儲存或其他處理\n",
    "    \"\"\"\n",
    "    h, w = seg_map.shape[:2]\n",
    "\n",
    "    # 預設 raw seg 顏色（與原 code 類似），若外部沒有提供則建立一組可重複使用的顏色\n",
    "    default_colors = np.array([\n",
    "        [128, 64, 128], [244, 35, 232], [70, 70, 70], [102, 102, 156],\n",
    "        [190, 153, 153], [153, 153, 153], [250, 170, 30], [220, 220, 0],\n",
    "        [107, 142, 35], [152, 251, 152], [70, 130, 180], [220, 20, 60],\n",
    "        [255, 0, 0], [0, 0, 142], [0, 0, 70], [0, 60, 100],\n",
    "        [0, 80, 100], [0, 0, 230], [119, 11, 32]\n",
    "    ], dtype=np.uint8)\n",
    "\n",
    "    n_classes = len(classes)\n",
    "    if default_colors.shape[0] < n_classes:\n",
    "        # 若 class 多於定義顏色，循環使用顏色\n",
    "        reps = int(np.ceil(n_classes / default_colors.shape[0]))\n",
    "        default_colors = np.tile(default_colors, (reps, 1))[:n_classes]\n",
    "\n",
    "    # raw seg 上色：根據 class index 把顏色取出\n",
    "    seg_rgb = default_colors[seg_map]  # HxWx3\n",
    "\n",
    "    # processed 顏色（人造 = 紅 / 自然 = 綠），可被外部覆寫\n",
    "    if processed_color_map is None:\n",
    "        processed_colors = np.zeros_like(default_colors)\n",
    "        for i, cls in enumerate(classes):\n",
    "            processed_colors[i] = [255, 0, 0] if cls in HUMAN_MADE else [0, 255, 0]\n",
    "    else:\n",
    "        # processed_color_map 可為 dict {idx: (r,g,b)} or list-like\n",
    "        processed_colors = np.zeros_like(default_colors)\n",
    "        if isinstance(processed_color_map, dict):\n",
    "            for i in range(n_classes):\n",
    "                if i in processed_color_map:\n",
    "                    processed_colors[i] = np.array(processed_color_map[i], dtype=np.uint8)\n",
    "                else:\n",
    "                    processed_colors[i] = default_colors[i]\n",
    "        else:\n",
    "            # list-like\n",
    "            arr = np.array(processed_color_map, dtype=np.uint8)\n",
    "            if arr.shape[0] >= n_classes:\n",
    "                processed_colors[:n_classes] = arr[:n_classes]\n",
    "            else:\n",
    "                processed_colors[:arr.shape[0]] = arr\n",
    "                processed_colors[arr.shape[0]:n_classes] = default_colors[arr.shape[0]:n_classes]\n",
    "\n",
    "    seg_processed_rgb = processed_colors[seg_map]\n",
    "\n",
    "    # 若未提供 seg_classified，根據 classes 判斷\n",
    "    if seg_classified is None:\n",
    "        seg_classified = np.zeros((h, w), dtype=np.int64)\n",
    "        for i, cls in enumerate(classes):\n",
    "            mask = (seg_map == i)\n",
    "            seg_classified[mask] = 1 if cls in HUMAN_MADE else 2\n",
    "\n",
    "    # 顯示（如果有 compare_images helper）\n",
    "    if show_compare:\n",
    "        try:\n",
    "            compare_images(img_rgb, seg_rgb, seg_processed_rgb, titles=['Original', 'Segmentation', 'Post-processed'])\n",
    "        except Exception:\n",
    "            # 若 compare_images 不可用，改用 mmcv.imshow 預覽（簡單 fallback）\n",
    "            try:\n",
    "                mmcv.imshow(img_rgb, win_name='Original')\n",
    "                mmcv.imshow(seg_rgb, win_name='Segmentation')\n",
    "                mmcv.imshow(seg_processed_rgb, win_name='Post-processed')\n",
    "            except Exception:\n",
    "                # 無法顯示時直接 pass\n",
    "                pass\n",
    "\n",
    "    return seg_rgb, seg_processed_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cc4072",
   "metadata": {},
   "source": [
    "## print funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78072e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(arr, name=\"array\", print_log =False):\n",
    "    \"\"\"\n",
    "    列印 2D numpy array 的基本統計量：\n",
    "    min, max, mean, Q1, Q3\n",
    "    \"\"\"\n",
    "    if not isinstance(arr, np.ndarray):\n",
    "        raise ValueError(\"arr 必須是 numpy array\")\n",
    "    if arr.ndim != 2:\n",
    "        raise ValueError(\"arr 必須是 H×W 的 2D array\")\n",
    "\n",
    "    a = arr.astype(float).reshape(-1)\n",
    "\n",
    "    q1 = np.percentile(a, 25)\n",
    "    q3 = np.percentile(a, 75)\n",
    "\n",
    "    if print_log:\n",
    "        print(f\"[{name}]\")\n",
    "        print(f\"  max : {a.max():.6f}\")\n",
    "        print(f\"  q3  : {q3:.6f}\")\n",
    "        print(f\"  mean: {a.mean():.6f}\")\n",
    "        print(f\"  q1  : {q1:.6f}\")\n",
    "        print(f\"  min : {a.min():.6f}\")\n",
    "\n",
    "    return a.max(), q3, a.mean(), q1, a.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3510e4eb",
   "metadata": {},
   "source": [
    "# main func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9666a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------- 影片 metadata --------------------\n",
    "def save_video_metadata(vid_path, npz_path=None):\n",
    "    \"\"\"\n",
    "    儲存單個影片的 metadata 到 npz 檔案。\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[Warning] Cannot open video: {vid_path}\")\n",
    "        return None\n",
    "    \n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_size = (height, width)\n",
    "    cap.release()\n",
    "    \n",
    "    name = os.path.splitext(os.path.basename(vid_path))[0]\n",
    "    metadata = {\n",
    "        name: {\n",
    "            \"frame_count\": frame_count,\n",
    "            \"frame_size\": frame_size,\n",
    "            \"file_name\": os.path.basename(vid_path)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if npz_path:\n",
    "        np.savez(npz_path, **metadata, allow_pickle=True)\n",
    "        print(f\"[INFO] Saved metadata to {npz_path}\")\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# -------------------- 處理單影片，每 n 幀計算 --------------------\n",
    "def process_and_save_video(video_path, output_folder, n_frames=30):\n",
    "    \"\"\"\n",
    "    處理單個影片，抽取每 n 幀計算 depth / segmentation / image change\n",
    "    並存成單獨 npz 檔案。\n",
    "    \"\"\"\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    output_npz = os.path.join(output_folder, f\"{video_name}.npz\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[Warning] 無法開啟影片: {video_path}\")\n",
    "        return\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_idx = 0\n",
    "    video_data = []\n",
    "\n",
    "    with tqdm(total=total_frames, desc=f\"Processing {video_name}\") as pbar:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if frame_idx % n_frames == 0:\n",
    "                frame_vector = []\n",
    "\n",
    "                # Depth\n",
    "                depth_result = compute_depth_map(frame, midas, midas_transform, device)\n",
    "                frame_vector.extend(print_stats(depth_result))\n",
    "\n",
    "                # Segmentation\n",
    "                img_rgb, seg_map, seg_classified, (human_ratio, nature_ratio) = compute_seg_frame(frame)\n",
    "                frame_vector.append(human_ratio)\n",
    "                frame_vector.append(nature_ratio)\n",
    "\n",
    "                # Image Change\n",
    "                metrics = compute_img_change(frame)\n",
    "                if metrics is not None:\n",
    "                    frame_vector.append(metrics[\"L1\"])\n",
    "                    frame_vector.append(metrics[\"1-SSIM\"])\n",
    "                    frame_vector.append(metrics[\"FlowMag\"])\n",
    "                else:\n",
    "                    frame_vector.extend([0.0, 0.0, 0.0])\n",
    "\n",
    "                frame_array = np.array(frame_vector, dtype=np.float32)\n",
    "                video_data.append(frame_array)\n",
    "\n",
    "            frame_idx += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # 轉成 2D np array 並存檔\n",
    "    if video_data:\n",
    "        video_data = np.stack(video_data, axis=0)\n",
    "        np.savez_compressed(output_npz, data=video_data)\n",
    "        print(f\"[INFO] Saved npz for video: {output_npz}\")\n",
    "\n",
    "    # 釋放記憶體\n",
    "    del video_data\n",
    "\n",
    "# -------------------- 批次處理資料夾 --------------------\n",
    "def process_folder_videos(folder_path, n_frames=30):\n",
    "    \"\"\"\n",
    "    處理資料夾中所有 mp4 影片，每個影片單獨存 npz。\n",
    "    \"\"\"\n",
    "    video_list = [\n",
    "        os.path.join(folder_path, f)\n",
    "        for f in os.listdir(folder_path)\n",
    "        if f.lower().endswith(\".mp4\")\n",
    "    ]\n",
    "    video_list = sorted(video_list)\n",
    "\n",
    "    for video_path in video_list:\n",
    "        # 儲存 metadata\n",
    "        save_video_metadata(video_path, npz_path=os.path.join(folder_path, f\"{os.path.splitext(os.path.basename(video_path))[0]}_meta.npz\"))\n",
    "        # 處理影片\n",
    "        process_and_save_video(video_path, output_folder=folder_path, n_frames=n_frames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab79f4",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4a882a9",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "for video in videos:\n",
    "    video_data= []\n",
    "    for frame in video:\n",
    "        frame_data = frame_data(frame)  #9個特徵值\n",
    "        video_data.append(frame_data) #  2d array (Time, Vector)\n",
    "\n",
    "    save_video_data(video_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1bb3ec",
   "metadata": {},
   "source": [
    "# 執行所有video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2199500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_folder_videos(video_folder, n_frames=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089dddb",
   "metadata": {},
   "source": [
    "#　查看特定frame 的深度 語意圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce4e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"C:/Users/yutse/OneDrive/桌面/cg/dataset_video/video/LFMG_04.MP4\"\n",
    "n_frames =15\n",
    "WANTED_FRAME_IDX = 777\n",
    "video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "output_npz = os.path.join(output_folder, f\"{video_name}.npz\")\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    " \n",
    "\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_idx = 0\n",
    "video_data = []\n",
    "\n",
    "with tqdm(total=total_frames, desc=f\"Processing {video_name}\") as pbar:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_idx  == WANTED_FRAME_IDX:\n",
    "            frame_vector = []\n",
    "\n",
    "            # Depth\n",
    "            depth_result = compute_depth_map(frame, midas, midas_transform, device)\n",
    "            viz_hw(depth_result, title=\"Depth Map\")\n",
    "            frame_vector.extend(print_stats(depth_result))\n",
    "\n",
    "            # Segmentation\n",
    "            img_rgb, seg_map, seg_classified, (human_ratio, nature_ratio) = compute_seg_frame(frame)\n",
    "            viz_seg_results(img_rgb, seg_map, seg_classified, show_compare=True)\n",
    "            frame_vector.append(human_ratio)\n",
    "            frame_vector.append(nature_ratio)\n",
    "\n",
    "            # Image Change\n",
    "            metrics = compute_img_change(frame)\n",
    "            if metrics is not None:\n",
    "                frame_vector.append(metrics[\"L1\"])\n",
    "                frame_vector.append(metrics[\"1-SSIM\"])\n",
    "                frame_vector.append(metrics[\"FlowMag\"])\n",
    "            else:\n",
    "                frame_vector.extend([0.0, 0.0, 0.0])\n",
    "\n",
    "            frame_array = np.array(frame_vector, dtype=np.float32)\n",
    "            video_data.append(frame_array)\n",
    "            break\n",
    "        frame_idx += 1\n",
    "        pbar.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
