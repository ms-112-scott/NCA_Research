# `E4-4.4.1_UrbanTales_GNCA_overfit.ipynb` 檔案分析

## 總體目標

此 Jupyter Notebook 的主要目的是進行一個「過擬合 (Overfitting)」測試。

其核心思想是驗證目前的 Growth Neural Cellular Automata (GNCA) 模型是否具備足夠的能力，在給定**單一目標圖像**的情況下，完全學習並重現該圖像的生長過程。這是一個重要的健全性檢查 (Sanity Check)，用以確保：
1.  模型架構有足夠的表達能力 (capacity)。
2.  訓練循環和損失函數的設置是正確且有效的。

如果模型無法在單一樣本上過擬合，那麼它很可能也無法在更複雜的、包含多個樣本的資料集上學習到有意義的規律。

## 執行流程

1.  **環境與資料載入**:
    - 導入 `torch`, `numpy` 等函式庫。
    - 使用 `create_simple_epoch_pool` 函式載入資料。此函式被設計為只讀取資料集中的**第一個樣本** (`all_cases[0]`)，並將其複製多次來建立一個只包含單一樣本的訓練池 (`Y_Pool`)。

2.  **模型與訓練設置**:
    - 初始化一個標準的 `CAModel` 神經網路模型。
    - 創建一個初始狀態 `X_Pool`，通常是從一個中央的「種子」狀態開始。
    - 定義損失函數 `custom_loss`，主要基於預測與目標之間的均方誤差 (MSE)。
    - 使用 Adam 優化器。

3.  **過擬合訓練 (`run_training`)**:
    - 進行一個長時間的訓練循環 (設定為 2000+ 次迭代)。
    - 在每一次迭代中，模型都從同一個種子狀態開始，試圖生長成目標圖像。
    - 整個訓練過程只針對**同一個目標**進行學習，目的是讓模型完美「記住」這一個樣本。

4.  **結果視覺化與監控**:
    - 在訓練過程中，定期（例如每 50 個 epoch）清除輸出並更新視覺化圖表。
    - `viz_loss`: 繪製訓練損失和評估損失的曲線，觀察損失是否穩定下降。
    - `viz_batch_channels` / `viz_batch_samples`: 顯示模型在訓練過程中生成的圖像，與目標圖像進行比較。
    - `viz_pool`: 視覺化展示樣本池中的狀態。

## 結論

這個筆記本是一個獨立的單元測試或實驗，用於驗證模型的基本學習能力。它的成功（即模型能夠在訓練後完美重現目標圖像，且損失降至很低）為後續在完整資料集上進行更複雜的、旨在實現「泛化 (Generalization)」能力的訓練提供了信心。
