# ====================================================
# region imports
# init_env.py - çµ±ä¸€ Notebook å¯¦é©—ç’°å¢ƒåˆå§‹åŒ–
# ====================================================
import sys
import os
import gc
import json
import glob
import random
import datetime
import tqdm
from pathlib import Path
from typing import Dict, List, Union, Callable, Optional, Tuple
import inspect

# ------------------------------------------------------------------------------
# ç¬¬ä¸‰æ–¹å¥—ä»¶
# ------------------------------------------------------------------------------
import numpy as np
import xarray as xr
import matplotlib.pylab as plt
from tqdm import trange
from IPython.display import clear_output, display, HTML
from scipy.ndimage import generic_filter

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as Optimizer
import torch.nn.init as init
from torch.utils.data import DataLoader, random_split

from torchsummary import summary

import plotly.io as pio

pio.renderers.default = "vscode"

# ------------------------------------------------------------------------------
# å°å…¥å°ˆæ¡ˆå‡½å¼åº«
# ------------------------------------------------------------------------------
from core_utils.plotting import *

from core_utils.viz_train import *

from core_utils.viz_batch_results import *

from E4_PI_NCA.utils.helper import *

from E4_PI_NCA.utils.dataNorm import NormalizeWrapper

from E4_PI_NCA.utils.NCA_dataset import NCA_Dataset

from E4_PI_NCA.utils.PinnLoss_v1 import *


# ------------------------------------------------------------------------------
# region æ•´ç†ç’°å¢ƒè³‡è¨Š
# ------------------------------------------------------------------------------
def show_env_info():
    print(f"ğŸ“¦ PyTorch: {torch.__version__}")
    print(f"ğŸ“¦ Numpy: {np.__version__}")
    print(
        f"ğŸ“¦ Matplotlib: {plt.__version__ if hasattr(plt, '__version__') else 'builtin'}"
    )
    print(f"ğŸ§  Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}")
    clear_output()


# optional: æ¸…ç† CUDA èˆ‡ cache
def reset_torch_env():
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    print("ğŸ§¹ Cleared CUDA cache and Python GC")


# ------------------------------------------------------------------------------
# region set_global_seed
# ------------------------------------------------------------------------------
def set_global_seed(seed: int = 42) -> None:
    """
    è¨­å®š Pythonã€NumPyã€PyTorch çš„éš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿çµæœå¯é‡ç¾ã€‚

    Parameters
    ----------
    seed : int, optional
        éš¨æ©Ÿç¨®å­æ•¸å€¼, é è¨­ 42
    """
    # Python random
    random.seed(seed)

    # NumPy
    np.random.seed(seed)

    # PyTorch CPU
    torch.manual_seed(seed)

    # PyTorch CUDA (å–®GPU & å¤šGPU)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

    # è¨­å®š cudnn ç‚º deterministicï¼Œç¢ºä¿å·ç©çµæœå¯é‡ç¾
    # åœ¨ debug/é–‹ç™¼éšæ®µå¯ä»¥å…ˆè¨­ç‚º deterministic=False, benchmark=True ä¾†åŠ é€Ÿ
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.benchmark = True

    print(f"[INFO] Global seed set to {seed}")


# ------------------------------------------------------------------------------
# region é è¨­åŸ·è¡Œ
# ------------------------------------------------------------------------------
clear_output()
print("âœ… Environment initialized. Use show_env_info() to check details.")
