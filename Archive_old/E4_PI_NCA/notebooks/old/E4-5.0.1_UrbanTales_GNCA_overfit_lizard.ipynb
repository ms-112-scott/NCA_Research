{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8a62e193",
      "metadata": {},
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "643cee71",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "[INFO] Global seed set to 1234\n"
          ]
        }
      ],
      "source": [
        "# 初始化整個實驗環境\n",
        "import sys\n",
        "sys.path.append(\"C:/Users/GAI/Desktop/Scott/NCA_Research\")\n",
        "\n",
        "from E4_PI_NCA.init_notebook_imports import *\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n",
        "set_global_seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be63c0e3",
      "metadata": {},
      "source": [
        "# helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3108bd6",
      "metadata": {},
      "source": [
        "chair\n",
        "    component\n",
        "        train\n",
        "        test\n",
        "    object\n",
        "        2d\n",
        "        3d\n",
        "            train\n",
        "            test\n",
        "\n",
        "chair\n",
        "    train\n",
        "        component\n",
        "        3d\n",
        "        2d\n",
        "    test\n",
        "        component\n",
        "        3d\n",
        "        2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "8f274776",
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 讀取 PNG、調整大小、轉成 Torch Tensor（CHW 格式）\n",
        "# ================================================================\n",
        "def read_png_to_chw_tensor(path: str, size: tuple[int, int] = None) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    讀取 PNG 並轉換成 [C, H, W] torch.Tensor\n",
        "    - size: 目標總尺寸 (含 padding)\n",
        "    - pad: 邊界補零像素數\n",
        "    \"\"\"\n",
        "    # ------------------------------------------------------------\n",
        "    # 1. 讀取圖片並轉成 RGBA\n",
        "    # ------------------------------------------------------------\n",
        "    img = Image.open(path).convert(\"RGBA\")\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # 2. 先縮小到 (W - 2*pad, H - 2*pad)\n",
        "    # ------------------------------------------------------------\n",
        "    if size is not None:\n",
        "        img = img.resize(size, Image.NEAREST)\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # 3. 套用 alpha 通道遮罩（避免背景殘留）\n",
        "    # ------------------------------------------------------------\n",
        "    img_np = np.array(img).astype(np.float32) / 255.0  # [H, W, 4]\n",
        "    alpha = img_np[..., 3:4]\n",
        "    img_np *= alpha  # 套用透明度\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # 4. 轉成 tensor [C, H, W]\n",
        "    # ------------------------------------------------------------\n",
        "    tensor = torch.from_numpy(img_np.transpose(2, 0, 1))  # [3, H, W]\n",
        "\n",
        "    return tensor\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 隨機四邊 padding（兩個 pool 對應一致）\n",
        "# ================================================================\n",
        "def random_pad_pair(\n",
        "    poolA: torch.Tensor, poolB: torch.Tensor, min_pad: int = 10, max_pad: int = 10\n",
        ") -> tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    對兩個 [B, C, H, W] tensor：\n",
        "      - 每個 batch 隨機產生上下左右 pad（0~max_pad）\n",
        "      - 使用相同 pad 對 A/B 處理\n",
        "      - 最後 resize 回原始 H, W 大小\n",
        "\n",
        "    Returns:\n",
        "        paddedA, paddedB: torch.Tensor，大小同原始 pool\n",
        "    \"\"\"\n",
        "    B, C, H, W = poolA.shape\n",
        "    paddedA_list, paddedB_list = [], []\n",
        "\n",
        "    for b in range(B):\n",
        "        # 隨機 pad 數值\n",
        "        pad_left = random.randint(min_pad, max_pad)\n",
        "        pad_right = random.randint(min_pad, max_pad)\n",
        "        pad_top = random.randint(min_pad, max_pad)\n",
        "        pad_bottom = random.randint(min_pad, max_pad)\n",
        "\n",
        "        pad_tuple = (pad_left, pad_right, pad_top, pad_bottom)\n",
        "\n",
        "        # pad\n",
        "        a_padded = F.pad(poolA[b], pad_tuple, mode=\"constant\", value=0)\n",
        "        b_padded = F.pad(poolB[b], pad_tuple, mode=\"constant\", value=0)\n",
        "\n",
        "        # resize 回原始大小\n",
        "        a_resized = F.interpolate(\n",
        "            a_padded.unsqueeze(0), size=(H, W), mode=\"bilinear\", align_corners=False\n",
        "        ).squeeze(0)\n",
        "        b_resized = F.interpolate(\n",
        "            b_padded.unsqueeze(0), size=(H, W), mode=\"bilinear\", align_corners=False\n",
        "        ).squeeze(0)\n",
        "\n",
        "        paddedA_list.append(a_resized)\n",
        "        paddedB_list.append(b_resized)\n",
        "\n",
        "    paddedA = torch.stack(paddedA_list, dim=0)\n",
        "    paddedB = torch.stack(paddedB_list, dim=0)\n",
        "    return paddedA, paddedB\n",
        "\n",
        "\n",
        "def create_seed_pool(pool: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    給定 BCHW tensor，根據 channel=3 (alpha 通道) 計算 alpha=1 像素的重心，\n",
        "    回傳一個新的全 0 tensor（同 shape），\n",
        "    並在每個 batch 的 channel=3、重心 pixel 位置設為 1.0。\n",
        "    \"\"\"\n",
        "    B, C, H, W = pool.shape\n",
        "    new_pool = torch.zeros_like(pool)\n",
        "\n",
        "    # 取出 alpha 通道 [B, 1, H, W]\n",
        "    alpha = pool[:, 3:4, :, :]\n",
        "\n",
        "    for b in range(B):\n",
        "        # 找出 alpha == 1 的像素座標\n",
        "        mask = (alpha[b, 0] == 1.0)\n",
        "        if mask.sum() == 0:\n",
        "            continue  # 若沒有 alpha=1 就跳過\n",
        "\n",
        "        ys, xs = torch.nonzero(mask, as_tuple=True)\n",
        "\n",
        "        # 計算重心（平均座標）\n",
        "        cy = torch.mean(ys.float())\n",
        "        cx = torch.mean(xs.float())\n",
        "\n",
        "        # 四捨五入取最近 pixel\n",
        "        cy = int(round(cy.item()))\n",
        "        cx = int(round(cx.item()))\n",
        "\n",
        "        # 安全界線檢查\n",
        "        cy = max(0, min(H - 1, cy))\n",
        "        cx = max(0, min(W - 1, cx))\n",
        "\n",
        "        # 在 new_pool 中標記重心 pixel\n",
        "        pad = 4\n",
        "        new_pool[b, 3, cy-pad:cy+pad, cx-pad:cx+pad] = 1.0\n",
        "\n",
        "    return new_pool\n",
        "\n",
        "\n",
        "\n",
        "def create_pools_from_img_path(config: dict)->tuple[torch.Tensor,torch.Tensor]:\n",
        "    path = config[\"system\"][\"img_path\"]\n",
        "    B = config[\"dataset\"][\"final_epoch_size\"]\n",
        "    C = config[\"model\"][\"channels\"]\n",
        "    H = config[\"dataset\"][\"img_size\"]\n",
        "    W = config[\"dataset\"][\"img_size\"]\n",
        "    \n",
        "    chw = read_png_to_chw_tensor(path, size=(H,W))  # [3, 128, 128]\n",
        "    # 建立空的 pool，假設共 B 個樣本與 C 通道\n",
        "    y_pool = torch.zeros((B, C, H, W), dtype=torch.float32)\n",
        "    x_pool = torch.zeros((B, C, H, W), dtype=torch.float32)\n",
        "    # 將圖片放入前 3 個通道\n",
        "    y_pool[:, :4, :, :] = chw\n",
        "    x_pool = create_seed_pool(y_pool)\n",
        "\n",
        "    x_pool, y_pool = random_pad_pair(x_pool, y_pool, min_pad=5, max_pad=100)\n",
        "    return x_pool, y_pool\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "eb2c7158",
      "metadata": {},
      "outputs": [],
      "source": [
        "def init_X(config: dict, y_pool: torch.Tensor) -> torch.Tensor:\n",
        "    B, C, H, W = y_pool.shape\n",
        "    x_pool = torch.zeros((B, C, H, W), dtype=torch.float32)\n",
        "\n",
        "    # 取出 alpha 通道 [B, 1, H, W]\n",
        "    alpha = y_pool[:, 3:4, :, :]\n",
        "\n",
        "    for b in range(B):\n",
        "        # 找出 alpha == 1 的像素座標\n",
        "        mask = (alpha[b, 0] == 1.0)\n",
        "        if mask.sum() == 0:\n",
        "            continue  # 若沒有 alpha=1 就跳過\n",
        "\n",
        "        ys, xs = torch.nonzero(mask, as_tuple=True)\n",
        "\n",
        "        # 計算重心（平均座標）\n",
        "        cy = torch.mean(ys.float())\n",
        "        cx = torch.mean(xs.float())\n",
        "\n",
        "        # 四捨五入取最近 pixel\n",
        "        cy = int(round(cy.item()))\n",
        "        cx = int(round(cx.item()))\n",
        "\n",
        "        # 安全界線檢查\n",
        "        cy = max(0, min(H - 1, cy))\n",
        "        cx = max(0, min(W - 1, cx))\n",
        "\n",
        "        # 在 x_pool 中標記重心 pixel\n",
        "        pad = 4\n",
        "        x_pool[b, 3, cy-pad:cy+pad, cx-pad:cx+pad] = 1.0\n",
        "\n",
        "    return x_pool"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8d51fc1",
      "metadata": {},
      "source": [
        "# define Neural Net"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b2abcf0",
      "metadata": {},
      "source": [
        "## model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "b524f293",
      "metadata": {},
      "outputs": [],
      "source": [
        "class CAModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Cellular Automata Model (Conv + perception kernels)\n",
        "    \"\"\"\n",
        "    def __init__(self, config:dict):\n",
        "        super().__init__()\n",
        "        self.channel_n = config[\"model\"][\"channels\"]\n",
        "        self.hidden_dim = config[\"model\"][\"hidden_dim\"]\n",
        "        self.kernel_count = config[\"model\"][\"kernel_count\"]\n",
        "        self.num_hidden_layers = config[\"model\"][\"num_hidden_layers\"]\n",
        "\n",
        "        # 建立 rule_block\n",
        "        self.rule_block = self.build_rule_block(\n",
        "            in_channels=self.channel_n * self.kernel_count,\n",
        "            hidden_dim=self.hidden_dim,\n",
        "            out_channels=self.channel_n,\n",
        "            num_hidden_layers=self.num_hidden_layers \n",
        "        )\n",
        "\n",
        "    def build_rule_block(self, in_channels: int, hidden_dim: int, out_channels: int, num_hidden_layers: int = 1) -> nn.Sequential:\n",
        "        \"\"\"\n",
        "        建立 rule block 的 Conv + Tanh 結構\n",
        "        \"\"\"\n",
        "        layers = [nn.Conv2d(in_channels, hidden_dim, kernel_size=1), nn.Tanh()]\n",
        "        # layers.append(nn.Conv2d(hidden_dim, hidden_dim, kernel_size=1))\n",
        "        # layers.append(nn.Tanh())\n",
        "        # layers.append(nn.Conv2d(hidden_dim, hidden_dim, kernel_size=1))\n",
        "        # layers.append(nn.Tanh())\n",
        "        for _ in range(num_hidden_layers):\n",
        "            layers.append(nn.Conv2d(hidden_dim, hidden_dim, kernel_size=1))\n",
        "            layers.append(nn.Tanh())\n",
        "        layers.append(nn.Conv2d(hidden_dim, out_channels, kernel_size=1))  #, bias=False\n",
        "        # layers.append(nn.Tanh())\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def perchannel_conv(self, x: torch.Tensor, filters: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        對每個 channel 做 depthwise convolution\n",
        "        x: [B, C, H, W]\n",
        "        filters: [filter_n, Hf, Wf]\n",
        "        return: [B, C * filter_n, H, W]\n",
        "        \"\"\"\n",
        "        b, ch, h, w = x.shape\n",
        "        device = x.device\n",
        "        filters = filters.to(device)\n",
        "        y = x.reshape(b * ch, 1, h, w)\n",
        "        y = F.pad(y, [1, 1, 1, 1], mode='circular')\n",
        "        y = F.conv2d(y, filters[:, None])\n",
        "        y = y.reshape(b, -1, h, w)\n",
        "        return y\n",
        "\n",
        "    def perception(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        定義感知 kernels: identity, sobel_x, sobel_y, laplacian\n",
        "        \"\"\"\n",
        "        device = x.device\n",
        "        ident = torch.tensor([[0.0, 0.0, 0.0],\n",
        "                              [0.0, 1.0, 0.0],\n",
        "                              [0.0, 0.0, 0.0]], device=device)\n",
        "        sobel_x = torch.tensor([[-1.0, 0.0, 1.0],\n",
        "                                [-2.0, 0.0, 2.0],\n",
        "                                [-1.0, 0.0, 1.0]], device=device)\n",
        "        lap = torch.tensor([[1.0, 2.0, 1.0],\n",
        "                            [2.0, -12.0, 2.0],\n",
        "                            [1.0, 2.0, 1.0]], device=device)\n",
        "        lbm = torch.tensor([[1/36, 1/9, 1/36],\n",
        "                            [1/9, 4/9, 1/9],\n",
        "                            [1/36, 1/9, 1/36]], device=device)\n",
        "        filters = torch.stack([ident, sobel_x, sobel_x.T, lap, lbm])\n",
        "        return self.perchannel_conv(x, filters)\n",
        "    \n",
        "\n",
        "    def forward_pass(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        單步更新\n",
        "        \"\"\"\n",
        "        check_tensor_nan_inf(x,\"model\")\n",
        "        y = self.perception(x)\n",
        "        check_tensor_nan_inf(y,\"model2\")\n",
        "        dx = self.rule_block(y)\n",
        "        check_tensor_nan_inf(dx,\"model3\")\n",
        "        no_change = x[:, :6, :, :]  # 前4 channel 保留\n",
        "        updated = x + dx * x[:, 2:3, :, :]\n",
        "        check_tensor_nan_inf(updated,\"model4\")\n",
        "        return torch.cat([no_change, updated[:, 6:, :, :]], dim=1)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, n_times: int = 1) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        多步迭代\n",
        "        \"\"\"\n",
        "        for _ in range(n_times):\n",
        "            x = self.forward_pass(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "468c8d4a",
      "metadata": {},
      "source": [
        "## EarlyStop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "115d9e7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "class EarlyStopper:\n",
        "    \"\"\"\n",
        "    Early stopping helper\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        self.patience = config[\"earlystop\"][\"patience\"]\n",
        "        self.min_delta = config[\"earlystop\"][\"delta\"]\n",
        "        self.counter = 0\n",
        "        self.best_loss = np.inf\n",
        "        self.early_stop = False\n",
        "\n",
        "    def step(self, loss):\n",
        "        if loss + self.min_delta < self.best_loss:\n",
        "            self.best_loss = loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        return self.early_stop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90b3a45b",
      "metadata": {},
      "source": [
        "## epoch step"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52551dda",
      "metadata": {},
      "source": [
        "### train step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "787091d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== 訓練函式 ======\n",
        "def train_one_epoch(\n",
        "    config: dict,\n",
        "    epoch_count: int,\n",
        "    model: nn.Module,\n",
        "    optimizer: Optimizer,\n",
        "    loss_fn: nn.Module,\n",
        "    Y_pool: np.array,\n",
        "    X_pool: np.array,\n",
        ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    執行一個 epoch 的訓練迴圈，回傳最後一個 batch 的 loss 與對應資料。\n",
        "\n",
        "    參數:\n",
        "        model: nn.Module, 神經網路模型\n",
        "        optimizer: PyTorch Optimizer\n",
        "        loss_fn: nn.Module, 損失函數\n",
        "        train_batch_size: int, 單次訓練的 batch 大小\n",
        "        item_pool_repeats: int, 將 epoch pool 複製的次數\n",
        "        repeats_per_epoch: int, 每個 epoch 重複迭代的次數\n",
        "        rollout_min: int, 最小演化步數\n",
        "        rollout_max: int, 最大演化步數\n",
        "\n",
        "    回傳:\n",
        "        tuple: (loss, Y_batch, X_batch, X_pred)\n",
        "            - loss: torch.Tensor, 最後一個 batch 的 loss\n",
        "            - Y_batch: torch.Tensor, 目標 batch\n",
        "            - X_batch: torch.Tensor, 模型輸入 batch\n",
        "            - X_pred: torch.Tensor, 模型輸出 batch\n",
        "    \"\"\"\n",
        "\n",
        "    train_batch_size = config[\"training\"][\"batch_size\"]\n",
        "    rollout_max = config[\"training\"][\"rollout_max\"]\n",
        "    total_epochs = config[\"training\"][\"total_epochs\"]\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # 隨機挑一個 batch\n",
        "    idx = torch.randint(0, len(Y_pool) - train_batch_size + 1, (1,))\n",
        "    Y_batch = Y_pool[idx : idx + train_batch_size].to(DEVICE)\n",
        "    X_batch = X_pool[idx : idx + train_batch_size].to(DEVICE).clone()\n",
        "    check_tensor_nan_inf([Y_batch, X_batch], \"train step1\")\n",
        "    with torch.no_grad():\n",
        "        batch_count = len(X_batch)\n",
        "        X_batch[-batch_count // 4 :] = init_X(config, X_batch[-batch_count // 4 :])\n",
        "        X_batch = X_batch.to(DEVICE)\n",
        "    check_tensor_nan_inf([Y_batch, X_batch], \"train step2\")\n",
        "    # 隨機決定演化步數\n",
        "    # rollout_steps = get_rollout_times(\n",
        "    #     epoch_count, max_epoch=total_epochs, max_n=rollout_max, scale=1\n",
        "    # )\n",
        "    rollout_steps=rollout_max\n",
        "\n",
        "    # 前向傳播\n",
        "    X_pred = model(X_batch, n_times=rollout_steps)\n",
        "    check_tensor_nan_inf([X_pred], \"train step3\")\n",
        "    # 更新pool\n",
        "    X_pool[idx : idx + train_batch_size] = X_pred\n",
        "    check_tensor_nan_inf([X_pool], \"train step4\")\n",
        "\n",
        "    # 計算 loss 並反向傳播\n",
        "    check_tensor_nan_inf([X_pred, Y_batch], \"train step5\")\n",
        "    loss_dict = loss_fn(config, X_pred, Y_batch)\n",
        "    check_tensor_nan_inf([loss_dict], \"train step6\")\n",
        "    total_loss = sum(loss_dict.values())\n",
        "\n",
        "    # 反向傳播更新梯度\n",
        "    optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    \n",
        "    Y_channels = Y_batch.shape[1]\n",
        "\n",
        "\n",
        "    batch_dict = {\n",
        "        \"Y\": Y_batch,\n",
        "        \"X0\": X_batch,\n",
        "        \"X1\": X_pred,\n",
        "        \"diff\": Y_batch - X_pred[:,:Y_channels],\n",
        "    }\n",
        "\n",
        "    return loss_dict, batch_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5430b6b",
      "metadata": {},
      "source": [
        "### eval step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "55cc8097",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_one_epoch(\n",
        "    config: dict,\n",
        "    y_pool: torch.Tensor,\n",
        "    model: torch.nn.Module,\n",
        "    loss_fn: Callable[[torch.Tensor, torch.Tensor], Dict[str, torch.Tensor]],\n",
        "    metric_fn: Callable[[torch.Tensor, torch.Tensor], Dict[str, torch.Tensor]] = None,\n",
        ") -> Tuple[Dict[str, torch.Tensor], Dict[str, torch.Tensor], np.ndarray]:\n",
        "    \"\"\"\n",
        "    在測試集上做評估，計算平均 loss 與 metric。\n",
        "    \"\"\"\n",
        "    rollout_steps = config[\"training\"][\"rollout_max\"]\n",
        "    model.eval()\n",
        "    total_loss_list = []\n",
        "    X_batch_list = []\n",
        "    X_pred_list = []\n",
        "    metrics_list = []\n",
        "\n",
        "    # 建立 epoch 的子區域池\n",
        "    Y_batch = y_pool[0:1].to(DEVICE)  # eval 模式只取一個樣本\n",
        "    X_batch = init_X(config, Y_batch).to(DEVICE)\n",
        "    check_tensor_nan_inf([Y_batch, X_batch], \"inside eval\")\n",
        "\n",
        "    rollout_steps = 20\n",
        "    for _ in range(rollout_steps):\n",
        "        X_batch_list.append(X_batch.clone())\n",
        "        check_tensor_nan_inf([X_batch_list, X_batch], \"inside eval2\")\n",
        "        X_batch = model(X_batch, n_times=1)\n",
        "        X_pred_list.append(X_batch.clone())\n",
        "\n",
        "        # 計算 loss\n",
        "        check_tensor_nan_inf([Y_batch, X_batch], \"inside eval3\")\n",
        "        loss_dict = loss_fn(config, X_batch, Y_batch)\n",
        "        check_tensor_nan_inf(loss_dict, \"inside eval4\")\n",
        "        total_loss = sum(loss_dict.values())\n",
        "        total_loss_list.append(total_loss)\n",
        "\n",
        "        # 計算 metric\n",
        "        if metric_fn is not None:\n",
        "            acc_metric = metric_fn(X_batch, Y_batch)\n",
        "            metrics_list.append(acc_metric)\n",
        "\n",
        "    x0 = torch.cat(X_batch_list, dim=0)\n",
        "    x1 = torch.cat(X_pred_list, dim=0)\n",
        "    y = Y_batch.repeat((rollout_steps, 1, 1, 1))\n",
        "\n",
        "    metrics_array = np.array(metrics_list)\n",
        "    Y_channels = y.shape[1]\n",
        "    batch_dict = {\n",
        "        \"Y\": y,\n",
        "        \"X0\": x0,\n",
        "        \"X1\": x1,\n",
        "        \"diff\": y - x1[:,:Y_channels],\n",
        "    }\n",
        "\n",
        "    return loss_dict, batch_dict, metrics_array"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7e56351",
      "metadata": {},
      "source": [
        "## training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "53588b50",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def save_checkpoint(model, optimizer, epoch, path):\n",
        "    torch.save(\n",
        "        {\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "        },\n",
        "        path,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "9ebb442c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "\n",
        "\n",
        "def run_training(\n",
        "    config: dict,\n",
        "    model: nn.Module,\n",
        "    optimizer: Optimizer,\n",
        "    loss_fn: Callable[[torch.Tensor, torch.Tensor], Dict[str, torch.Tensor]],\n",
        "    metric_fn: Callable[[torch.Tensor, torch.Tensor], Dict[str, torch.Tensor]] = None,\n",
        "    lr_sched: Optional[_LRScheduler] = None,\n",
        "    output_path: str = \"./output\",\n",
        ") -> None:\n",
        "\n",
        "    total_epochs = config[\"training\"][\"total_epochs\"]\n",
        "    save_interval = config[\"training\"][\"save_interval\"]\n",
        "\n",
        "    train_loss_log: list[float] = []\n",
        "    eval_loss_log: list[float] = []\n",
        "    eval_loss = 0\n",
        "    eval_metrics: List[np.ndarray] = []\n",
        "\n",
        "    early_stopper = EarlyStopper(config)\n",
        "    X_Pool, Y_Pool = create_pools_from_img_path(config)\n",
        "    X_Pool=X_Pool.to(DEVICE)\n",
        "    Y_Pool=Y_Pool.to(DEVICE)\n",
        "\n",
        "    check_tensor_nan_inf([Y_Pool, X_Pool], \"init_check\")\n",
        "\n",
        "    for epoch in trange(total_epochs, desc=\"Training Epochs\"):\n",
        "        # print(f\"epoch {epoch} start ------------------------------------\")\n",
        "        # ===== Training step =====\n",
        "        train_loss_dict, train_batch_dict = train_one_epoch(\n",
        "            config, epoch, model, optimizer, loss_fn, Y_Pool, X_Pool\n",
        "        )\n",
        "        train_loss = sum(train_loss_dict.values())\n",
        "        train_loss_log.append(train_loss.item())\n",
        "\n",
        "        if lr_sched is not None:\n",
        "            lr_sched.step()\n",
        "\n",
        "        # ===== Eval step =====\n",
        "        with torch.no_grad():\n",
        "            check_tensor_nan_inf([X_Pool, Y_Pool], \"eval check\")\n",
        "            X_Pool, Y_Pool = sort_pool_by_mse(X_Pool, Y_Pool)\n",
        "            check_tensor_nan_inf([X_Pool, Y_Pool], \"eval check2\")\n",
        "            eval_loss_dict, eval_batch_dict, eval_metric = evaluate_one_epoch(\n",
        "                config, Y_Pool, model, loss_fn, metric_fn\n",
        "            )\n",
        "            check_tensor_nan_inf(\n",
        "                [eval_loss_dict, eval_batch_dict, eval_metric], \"eval check3\"\n",
        "            )\n",
        "            eval_metrics.append(eval_metric)\n",
        "            if len(eval_metrics) > 1000:  # 或自己決定長度\n",
        "                eval_metrics.pop(0)\n",
        "\n",
        "            eval_loss = sum(eval_loss_dict.values())\n",
        "            eval_loss_log.append(eval_loss.item())\n",
        "\n",
        "\n",
        "        # ===== Visualization & Logging =====\n",
        "        if (epoch + 1) % 50 == 0:\n",
        "            clear_output(wait=True)\n",
        "            print_loss_dict(train_loss_dict, eval_loss_dict)\n",
        "            viz_loss(\n",
        "                train_loss_log, eval_loss_log, log_scale=True, window=total_epochs // 20\n",
        "            )\n",
        "            plt_acc_over_time(eval_metrics, title=\"L2 Metric\", ylabel=\"L2 Error\")\n",
        "            print(\"train epoch\")\n",
        "            viz_batch_channels(train_batch_dict, show_channels=(5,10))\n",
        "            viz_batch_samples(train_batch_dict, channel_start=6)\n",
        "            # plot_HW3(to_HWC(Y_Pool[0,6:9]))\n",
        "            # plot_HW3(to_HWC(train_batch_dict[\"X0\"][0,6:9]))\n",
        "            viz_pool(X_Pool[:, 6:9, :, :], step_i=epoch)\n",
        "            # viz_batch_channels(eval_batch_dict)\n",
        "\n",
        "        # ===== Checkpoint =====\n",
        "        if (epoch + 1) % save_interval == 0:\n",
        "            save_checkpoint(\n",
        "                model,\n",
        "                optimizer,\n",
        "                epoch + 1,\n",
        "                f\"{output_path}/checkpoint_epoch_{epoch+1}.pth\",\n",
        "            )\n",
        "\n",
        "        # ===== Early stopping =====\n",
        "        if early_stopper.step(train_loss) and epoch > 500:\n",
        "            print(f\"Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "        # ---- Early stop if train loss is NaN ----\n",
        "        check_tensor_nan_inf([train_loss_dict, eval_loss_dict], \"loss_dict check\")\n",
        "        if torch.isnan(train_loss):\n",
        "            print_loss_dict(train_loss_dict, eval_loss_dict)\n",
        "            print(f\"NaN detected in train loss at epoch {epoch}, stopping training.\")\n",
        "            break\n",
        "\n",
        "        # ===== Memory cleanup 每個 epoch 強制釋放 =====\n",
        "        del (\n",
        "            train_loss_dict,\n",
        "            train_batch_dict,\n",
        "            eval_loss_dict,\n",
        "            eval_batch_dict,\n",
        "            eval_metric,\n",
        "        )\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    # ===== Final save =====\n",
        "    try:\n",
        "        viz_loss(\n",
        "            train_loss_log,\n",
        "            eval_loss_log,\n",
        "            log_scale=True,\n",
        "            window=total_epochs // 20,\n",
        "            save_path=f\"{output_path}/loss\",\n",
        "        )\n",
        "    except:\n",
        "        pass\n",
        "    save_checkpoint(model, optimizer, total_epochs, f\"{output_path}/model_Final.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a2de19c",
      "metadata": {},
      "source": [
        "## loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "55bce453",
      "metadata": {},
      "outputs": [],
      "source": [
        "def divergence_loss(u, v):\n",
        "    # u, v shape: [B, 1, H, W]  (速度分量)\n",
        "    du_dx = torch.gradient(u, dim=-1)[0]  # ∂u/∂x\n",
        "    dv_dy = torch.gradient(v, dim=-2)[0]  # ∂v/∂y\n",
        "    div = du_dx + dv_dy\n",
        "    return torch.mean(div**2)  # L2 loss on divergence\n",
        "\n",
        "\n",
        "def data_mse_loss(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    計算 x 與 y 之間的 MSE loss\n",
        "    \"\"\"\n",
        "    mse = nn.MSELoss()\n",
        "    x = x[:, 6:11, :, :]  # 只取前 7 個 channel\n",
        "    y = y[:, 6:11, :, :]\n",
        "    loss = mse(x, y)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def obstacle_loss(x: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    檢查 obstacle cell (mask=0) 內，其他 channel 的值應該趨近於 0\n",
        "\n",
        "    Args:\n",
        "        x: Tensor [B, C, H, W], channel 0 = geo_mask (1=air, 0=object)\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: scalar loss\n",
        "    \"\"\"\n",
        "    mask = x[:, 2:3, ...]  # [B, 1, H, W]\n",
        "    phys = x[:, 6:9, ...]  # [B, 7, H, W] 取前 7 個物理量通道\n",
        "\n",
        "    obj_mask = 1.0 - mask  # object cell = 1, air = 0\n",
        "    masked_phys = phys * obj_mask  # 只保留物體內的值\n",
        "    loss = torch.mean(masked_phys**2)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def fft_loss(x: torch.Tensor, y: torch.Tensor, norm: str = \"L2\") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute per-channel FFT loss between x and y.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x, y : torch.Tensor\n",
        "        Input and target tensors, shape = (B, C, H, W)\n",
        "    norm : str\n",
        "        'L1' or 'L2' for difference metric\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        Scalar loss\n",
        "    \"\"\"\n",
        "    # FFT: compute 2D FFT per channel\n",
        "    X_fft = torch.fft.fft2(x[:, 6:9, ...], norm=\"ortho\")  # (B, C, H, W), complex\n",
        "    Y_fft = torch.fft.fft2(y[:, 6:9, ...], norm=\"ortho\")\n",
        "\n",
        "    # Compute magnitude difference\n",
        "    diff = torch.abs(X_fft - Y_fft)  # magnitude difference\n",
        "\n",
        "    if norm.upper() == \"L1\":\n",
        "        loss = diff.mean()\n",
        "    elif norm.upper() == \"L2\":\n",
        "        loss = (diff**2).mean()\n",
        "    else:\n",
        "        raise ValueError(\"norm should be 'L1' or 'L2'\")\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def Uvel_loss(x: torch.Tensor):\n",
        "    Uped_cal = torch.sqrt(x[:, 6:7, ...] ** 2 + x[:, 7:8, ...] ** 2 + 1e-8)  # (b,c,H,W)\n",
        "    diff = torch.abs(x[:, 8:9, ...] - Uped_cal) \n",
        "    loss = (diff**2).mean()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def custom_loss(config: dict, x: torch.Tensor, y: torch.Tensor) -> dict:\n",
        "    w_mse = config[\"loss_weights\"][\"mse\"]\n",
        "    # w_obstacel = config[\"loss_weights\"][\"obstacle\"]\n",
        "    w_uvel = config[\"loss_weights\"][\"uvel\"]\n",
        "    return {\n",
        "        \"mse_loss\": w_mse * data_mse_loss(x, y)/1e-2,\n",
        "        # \"obstacle_loss\": w_obstacel * obstacle_loss(x)/1e-4,\n",
        "        \"Uvel_loss\": w_uvel * Uvel_loss(x)/1e-2,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1437a473",
      "metadata": {},
      "source": [
        "## metric function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "72f20a7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def acc_metric(\n",
        "    pred: torch.Tensor,\n",
        "    target: torch.Tensor,\n",
        "    metric_type: str = \"L2\",\n",
        ") -> np.array:\n",
        "    \"\"\"\n",
        "    計算模型精度 metric, 支持用 pred 的第0 channel作為 mask.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    pred : torch.Tensor\n",
        "        模型預測, shape = (B, C, H, W)\n",
        "    target : torch.Tensor\n",
        "        Ground truth, shape = (B, C, H, W)\n",
        "    use_pred_mask : bool\n",
        "        是否用 pred 的第0 channel作為 mask (1 = 計算, 0 = 忽略)\n",
        "    metric_type : str\n",
        "        \"L1\", \"L2\", \"relative\"\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        scalar metric\n",
        "    \"\"\"\n",
        "    pred = pred[:, :9, :, :]\n",
        "    target = target[:, :9, :, :]\n",
        "\n",
        "    if metric_type.upper() == \"L1\":\n",
        "        return torch.mean(torch.abs(pred - target)).detach().cpu().numpy()\n",
        "    elif metric_type.upper() == \"L2\":\n",
        "        return torch.mean((pred - target) ** 2).detach().cpu().numpy()\n",
        "    elif metric_type.lower() == \"relative\":\n",
        "        return (\n",
        "            torch.mean(torch.abs(pred - target) / (torch.abs(target) + 1e-8))\n",
        "            .detach()\n",
        "            .cpu()\n",
        "            .numpy()\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(\"metric_type should be 'L1', 'L2', or 'relative'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbad5f15",
      "metadata": {},
      "source": [
        "# main process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "de6e8a68",
      "metadata": {},
      "outputs": [],
      "source": [
        "CONFIG = {\n",
        "    \"system\": {\n",
        "        \"device\": DEVICE,\n",
        "        \"output_path\": get_output_path(),\n",
        "        \"img_path\": r\"C:\\Users\\GAI\\Desktop\\Scott\\NCA_Research\\dataset\\lizard.png\",\n",
        "        \"channel_names\": [\n",
        "            \"geo_mask\",\n",
        "            \"topo\",\n",
        "            \"uped\",\n",
        "            \"vped\",\n",
        "            \"Uped\",\n",
        "            \"TKEped\",\n",
        "            \"Tuwped\",\n",
        "        ],\n",
        "    },\n",
        "    \"dataset\": {\n",
        "        \"dataset_npz_path\": \"../dataset/all_cases.npz\",\n",
        "        \"dataset_size\": (64, 64),\n",
        "        \"final_epoch_size\": 1024,\n",
        "        \"img_size\": 64,\n",
        "    },\n",
        "    \"model\": {\n",
        "        \"channels\": [16, 18, 20, 22, 24],\n",
        "        \"hidden_dim\": 256,\n",
        "        \"kernel_count\": 5,\n",
        "        \"num_hidden_layers\": [2, 3, 4],\n",
        "    },\n",
        "    \"training\": {\n",
        "        \"total_epochs\": 2000,\n",
        "        \"batch_size\": [8, 12, 16],\n",
        "        \"epoch_item_repeat_num\": 2,\n",
        "        \"epoch_pool_size\": 1024 // 2,  # final_epoch_size/epoch_item_repeat_num\n",
        "        \"repeat_num_per_epoch\": 1,\n",
        "        \"rollout_min\": 1,\n",
        "        \"rollout_max\": 8,\n",
        "        \"save_interval\": 200,\n",
        "    },\n",
        "    \"earlystop\": {\n",
        "        \"patience\": 150,\n",
        "        \"delta\": 1e-4,\n",
        "    },\n",
        "    \"channels\": {\n",
        "        \"bc\": [0, 1, 2, 3],\n",
        "        \"ic\": [4, 5],\n",
        "    },\n",
        "    \"loss_weights\": {\n",
        "        \"mse\": [1.0, 2.0, 3.0],\n",
        "        # \"obstacle\": [1.0, 2.0, 3.0],\n",
        "        \"uvel\": [1.0, 2.0, 3.0],\n",
        "    },\n",
        "    \"optim\": {\"lr\": 1e-3},\n",
        "}\n",
        "\n",
        "\n",
        "OPTIONS_PATHS = [\n",
        "    # (\"dataset\", \"final_epoch_size\"),\n",
        "    # (\"model\", \"hidden_dim\"),\n",
        "    (\"model\", \"channels\"),\n",
        "    # (\"model\", \"hidden_dim\"),\n",
        "    (\"model\", \"num_hidden_layers\"),\n",
        "    (\"training\", \"batch_size\"),\n",
        "    (\"loss_weights\", \"mse\"),\n",
        "    # (\"loss_weights\", \"obstacle\"),\n",
        "    (\"loss_weights\", \"uvel\"),\n",
        "    #     (\"training\", \"rollout_max\"),\n",
        "    # (\"optim\", \"lr\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "3ff0d89d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "def resolve_list_options(config: dict, key_paths: list[tuple]) -> dict:\n",
        "    new_config = json.loads(json.dumps(config))  # 深拷貝乾淨版本\n",
        "\n",
        "    for path in key_paths:\n",
        "        d = new_config\n",
        "        for k in path[:-1]:\n",
        "            d = d[k]\n",
        "        last_key = path[-1]\n",
        "        if isinstance(d.get(last_key), list):\n",
        "            d[last_key] = random.choice(d[last_key])\n",
        "    \n",
        "    return new_config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93e4db92",
      "metadata": {},
      "source": [
        "# batch run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "ea6db701",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========== Loss Summary ==========\n",
            "Train Losses:\n",
            "  mse_loss: 0.0000 |   Uvel_loss: 0.0000 | \n",
            "\n",
            "Eval Losses:\n",
            "  mse_loss: 0.0000 |   Uvel_loss: 0.0000 | \n",
            "\n",
            "==================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Font 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\n",
            "Font 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\n",
            "Font 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\n",
            "Font 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\n",
            "Font 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\n",
            "Font 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\n",
            "Font 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\n",
            "Font 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epochs:   2%|▏         | 49/2000 [00:22<14:56,  2.18it/s]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "zero-size array to reduction operation minimum which has no identity",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[111]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     15\u001b[39m lr_sched = torch.optim.lr_scheduler.StepLR(optimizer, step_size=\u001b[32m500\u001b[39m, gamma=\u001b[32m0.5\u001b[39m)\n\u001b[32m     17\u001b[39m model_path = get_output_path()\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43macc_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr_sched\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr_sched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# 確保目錄存在再寫入\u001b[39;00m\n\u001b[32m     30\u001b[39m os.makedirs(model_path, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 73\u001b[39m, in \u001b[36mrun_training\u001b[39m\u001b[34m(config, model, optimizer, loss_fn, metric_fn, lr_sched, output_path)\u001b[39m\n\u001b[32m     70\u001b[39m     viz_batch_samples(train_batch_dict, channel_start=\u001b[32m6\u001b[39m)\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# plot_HW3(to_HWC(Y_Pool[0,6:9]))\u001b[39;00m\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# plot_HW3(to_HWC(train_batch_dict[\"X0\"][0,6:9]))\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[43mviz_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_Pool\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_i\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m     \u001b[38;5;66;03m# viz_batch_channels(eval_batch_dict)\u001b[39;00m\n\u001b[32m     75\u001b[39m \n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# ===== Checkpoint =====\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (epoch + \u001b[32m1\u001b[39m) % save_interval == \u001b[32m0\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Users/GAI/Desktop/Scott/NCA_Research\\core_utils\\viz_train.py:86\u001b[39m, in \u001b[36mviz_pool\u001b[39m\u001b[34m(pool, step_i, output_path, title, show_channel, show_all)\u001b[39m\n\u001b[32m     81\u001b[39m     imwrite(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, (tiled_pool * \u001b[32m255\u001b[39m).astype(np.uint8))\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# 6️⃣ 顯示圖片\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m vmin = tiled_pool.min().item()\n\u001b[32m     87\u001b[39m vmax = tiled_pool.max().item()\n\u001b[32m     88\u001b[39m plt.imshow(tiled_pool, vmin=vmin, vmax=vmax, cmap=\u001b[33m\"\u001b[39m\u001b[33mjet\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GAI\\miniconda3\\envs\\pytorch-py311\\Lib\\site-packages\\numpy\\_core\\_methods.py:48\u001b[39m, in \u001b[36m_amin\u001b[39m\u001b[34m(a, axis, out, keepdims, initial, where)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_amin\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     47\u001b[39m           initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n",
            "\u001b[31mValueError\u001b[39m: zero-size array to reduction operation minimum which has no identity"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import traceback\n",
        "import os\n",
        "import torch\n",
        "import gc  # Python garbage collector\n",
        "\n",
        "for run_id in range(50):\n",
        "    remove_empty_dirs(r\"C:\\Users\\GAI\\Desktop\\Scott\\NCA_Research\\E4_PI_NCA\")\n",
        "    # try:\n",
        "    cfg = resolve_list_options(CONFIG, OPTIONS_PATHS)\n",
        "    print(f\"Run {run_id}:\\n{cfg}\")\n",
        "\n",
        "    model = CAModel(cfg).to(DEVICE)\n",
        "    optimizer = Optimizer.Adam(model.parameters(), lr=cfg[\"optim\"][\"lr\"])\n",
        "    lr_sched = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.5)\n",
        "\n",
        "    model_path = get_output_path()\n",
        "\n",
        "    run_training(\n",
        "        cfg,\n",
        "        model,\n",
        "        optimizer,\n",
        "        loss_fn=custom_loss,\n",
        "        metric_fn=acc_metric,\n",
        "        lr_sched=lr_sched,\n",
        "        output_path=model_path,\n",
        "    )\n",
        "\n",
        "    # 確保目錄存在再寫入\n",
        "    os.makedirs(model_path, exist_ok=True)\n",
        "    config_file_path = os.path.join(model_path, \"config.json\")\n",
        "    with open(config_file_path, \"w\") as f:\n",
        "        json.dump(cfg, f, indent=4)\n",
        "\n",
        "    # except Exception as e:\n",
        "    #     log_file = f\"{model_path}/training_error.log\"\n",
        "    #     with open(log_file, \"a\") as log_f:\n",
        "    #         log_f.write(f\"Run {run_id} failed:\\n\")\n",
        "    #         log_f.write(traceback.format_exc())\n",
        "    #         log_f.write(\"\\n\" + \"-\"*80 + \"\\n\")\n",
        "    #     print(f\"Run {run_id} failed. See {log_file} for details.\")\n",
        "\n",
        "    # finally:\n",
        "    #     # -----------------------------\n",
        "    #     # 釋放 GPU 記憶體\n",
        "    #     # -----------------------------\n",
        "    #     del model\n",
        "    #     del optimizer\n",
        "    #     del lr_sched\n",
        "    #     torch.cuda.empty_cache()\n",
        "\n",
        "    #     # -----------------------------\n",
        "    #     # 釋放 Python 物件\n",
        "    #     # -----------------------------\n",
        "    #     gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0c4ff5c",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "45a7ffdd",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "cc5ad5da",
      "metadata": {},
      "source": [
        "# After training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a394116d",
      "metadata": {},
      "source": [
        "## viz pngs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abed3a08",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def show_all_png(root_dir):\n",
        "    png_files = []\n",
        "    for dirpath, _, filenames in os.walk(root_dir):\n",
        "        for f in filenames:\n",
        "            if f.lower().endswith(\".png\"):\n",
        "                png_files.append(os.path.join(dirpath, f))\n",
        "\n",
        "    if not png_files:\n",
        "        print(\"No PNG files found.\")\n",
        "        return\n",
        "\n",
        "    for img_path in png_files:\n",
        "        print(f\"Showing {img_path}\")\n",
        "        img = mpimg.imread(img_path)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(os.path.relpath(img_path, root_dir))  # 不顯示 root_dir 之前的路徑\n",
        "        plt.show()\n",
        "\n",
        "# 使用範例\n",
        "show_all_png(r\"C:\\Users\\GAI\\Desktop\\Scott\\NCA_Research\\E4_PI_NCA\\outputs\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10dcfb6d",
      "metadata": {},
      "source": [
        "# test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5048cfab",
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "create_epoch_pool() missing 1 required positional argument: 'config'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m os.makedirs(output_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# --- 初始化資料 ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m Y_batch = \u001b[43mcreate_epoch_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.to(DEVICE)  \u001b[38;5;66;03m# [1, 32, 64, 64]\u001b[39;00m\n\u001b[32m     12\u001b[39m X_batch = init_X(Y_batch)  \u001b[38;5;66;03m# [batch, channel, H, W]\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 假設模型已經載入並設定 eval\u001b[39;00m\n",
            "\u001b[31mTypeError\u001b[39m: create_epoch_pool() missing 1 required positional argument: 'config'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import imageio\n",
        "from PIL import Image  # 用來 resize\n",
        "\n",
        "output_dir = \"temp_frames\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# --- 初始化資料 ---\n",
        "Y_batch = create_epoch_pool(mode=\"eval\").to(DEVICE)  # [1, 32, 64, 64]\n",
        "X_batch = init_X(Y_batch)  # [batch, channel, H, W]\n",
        "\n",
        "# 假設模型已經載入並設定 eval\n",
        "load_model = CAModel(channel_n=CHANNELS).to(DEVICE)\n",
        "load_model.load_state_dict(torch.load(f\"{model_path}/model.pth\"))\n",
        "load_model.eval()\n",
        "\n",
        "rollout_steps = 50\n",
        "frames = []\n",
        "target_size = (1024, 1024)  # (W, H)\n",
        "\n",
        "for t in range(rollout_steps):\n",
        "    # 每步 rollout\n",
        "    X_batch = load_model(X_batch, n_times=1)\n",
        "\n",
        "    # 取第一個 batch 的前三個 channel作 RGB\n",
        "    x_np = X_batch[0, 4:7].detach().cpu().numpy()  # shape: [3, H, W]\n",
        "    frame = np.transpose(x_np, (1, 2, 0))         # shape: [H, W, 3]\n",
        "    frame = np.clip(frame, 0, 1)                  # 確保值在 0~1\n",
        "    frame_uint8 = (frame * 255).astype(np.uint8)\n",
        "\n",
        "    # resize\n",
        "    img = Image.fromarray(frame_uint8)\n",
        "    img = img.resize(target_size, resample=Image.BILINEAR)\n",
        "    frame_resized = np.array(img)\n",
        "\n",
        "    # 選擇是否存單張 PNG\n",
        "    frame_path = os.path.join(output_dir, f\"{t:03d}.png\")\n",
        "    imageio.imwrite(frame_path, frame_resized)\n",
        "\n",
        "    # 累積成影片幀\n",
        "    frames.append(frame_resized)\n",
        "\n",
        "# 儲存成 mp4\n",
        "video_path = f\"{model_path}/output.mp4\"\n",
        "imageio.mimsave(video_path, frames, fps=3)\n",
        "print(\"Saved mp4:\", video_path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch-py311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
