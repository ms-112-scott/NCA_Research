{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a62e193",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1253,
   "id": "c580b1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "[INFO] Global seed set to 1234\n"
     ]
    }
   ],
   "source": [
    "# 初始化整個實驗環境\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/GAI/Desktop/Scott/NCA_Research\")\n",
    "\n",
    "from E4_PI_NCA.init_notebook_imports import *\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n",
    "set_global_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d9d1b7",
   "metadata": {},
   "source": [
    "# Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1254,
   "id": "850c2c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def camodel_summary(model, input_size=(20, 64, 64), batch_size=2, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    列印 CAModel shape summary\n",
    "    Args:\n",
    "        model: CAModel 實例\n",
    "        input_size: tuple, (C, H, W)\n",
    "        batch_size: int\n",
    "        device: str\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # 隨機輸入\n",
    "    x = torch.randn(batch_size, *input_size, device=device)\n",
    "\n",
    "    print(\"=\"*50)\n",
    "    print(\"=== CAModel Summary ===\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    # Perception filters\n",
    "    print(\"Perception Filters:\")\n",
    "    print(f\"filters: shape={tuple(model.filters.shape)}, requires_grad={model.filters.requires_grad}\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    # Perception conv shape\n",
    "    y = model.perception(x)\n",
    "    print(f\"[Perception] {tuple(x.shape)} -> {tuple(y.shape)}\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    # UNet Forward\n",
    "    xi = y\n",
    "    skips = []\n",
    "\n",
    "    print(\"UNet Forward:\")\n",
    "    for i, enc in enumerate(model.unet.encs):\n",
    "        xi_in = xi\n",
    "        xi = enc(xi)\n",
    "        skips.append(xi)\n",
    "        print(f\"[Encoder {i}]: {tuple(xi_in.shape)} -> {tuple(xi.shape)}\")\n",
    "        if i < len(model.unet.pools):\n",
    "            xi_in = xi\n",
    "            xi = model.unet.pools[i](xi)\n",
    "            print(f\"[Pool {i}]: {tuple(xi_in.shape)} -> {tuple(xi.shape)}\")\n",
    "\n",
    "    xi_in = xi\n",
    "    xi = model.unet.bottleneck(xi)\n",
    "    print(f\"[Bottleneck]: {tuple(xi_in.shape)} -> {tuple(xi.shape)}\")\n",
    "    # for skip in skips:\n",
    "    #     print(\"skip shape:\", skip.shape)\n",
    "    \n",
    "    print(\"\\nups\",model.unet.ups,\n",
    "    \"\\ndecs\",model.unet.decs)\n",
    "    # Decoder\n",
    "    for i, (up, dec, skip) in enumerate(zip(model.unet.ups, model.unet.decs, skips[::-1])):\n",
    "        xi_in = xi\n",
    "        print(\"inside  xi_in\",  xi_in.shape)\n",
    "        xi = up(xi)\n",
    "        print(\"inside  xi\",  xi.shape)\n",
    "        print(\"inside  skip\",  skip.shape)\n",
    "        xi = torch.cat([skip, xi], dim=1)\n",
    "        print(\"inside  xi\",  xi.shape)\n",
    "        print(dec)\n",
    "        xi = dec(xi)\n",
    "        print(f\"[Decoder {i}]: {tuple(xi_in.shape)} -> {tuple(xi.shape)}\")\n",
    "\n",
    "    xi_in = xi\n",
    "    print(\"\\n\\nFinal Conv:\", \n",
    "          xi.shape)\n",
    "    out_unet = model.unet.final_conv(xi)\n",
    "    print(f\"[FinalConv]: {tuple(xi_in.shape)} -> {tuple(out_unet.shape)}\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    # forward_pass shape\n",
    "    out_pass = model.forward_pass(x)\n",
    "    print(f\"[forward_pass] {tuple(x.shape)} -> {tuple(out_pass.shape)}\")\n",
    "    print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8e0389",
   "metadata": {},
   "source": [
    "## init_dataset_and_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1255,
   "id": "ac98bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dataset_and_loader(config, npz_dict):\n",
    "    channel_names = config[\"system\"][\"channel_names\"]\n",
    "    pool_size = config[\"dataset\"][\"pool_size\"]\n",
    "    channels = config[\"model\"][\"channels\"]\n",
    "    batch_size = config[\"training\"][\"batch_size\"]\n",
    "\n",
    "    dataset = NCA_Dataset(\n",
    "        npz_dict[\"data\"], channel_names, pool_size=(pool_size, channels)\n",
    "    )\n",
    "\n",
    "    # # 設定比例\n",
    "    # train_ratio = 0.7\n",
    "    # val_ratio   = 0.2\n",
    "    # test_ratio  = 0.1\n",
    "\n",
    "    # # 計算每個子集大小\n",
    "    # total_len = len(dataset)\n",
    "    # train_len = int(total_len * train_ratio)\n",
    "    # val_len   = int(total_len * val_ratio)\n",
    "    # test_len  = total_len - train_len - val_len  # 保證總數一致\n",
    "\n",
    "    def collate_with_indices(batch):\n",
    "        \"\"\"\n",
    "        將 Dataset 回傳的 [(idx, x, y), (idx, x, y), ...] 組成 batch。\n",
    "        \"\"\"\n",
    "        indices = [item[0] for item in batch]\n",
    "        xs = torch.stack([item[1] for item in batch], dim=0)\n",
    "        ys = torch.stack([item[2] for item in batch], dim=0)\n",
    "        return indices, xs, ys\n",
    "\n",
    "    train_len = 1\n",
    "    val_len = 0\n",
    "    test_len = 0\n",
    "\n",
    "    print(f\"ataset lengths: train={train_len}, val={val_len}, test={test_len}\")\n",
    "    # # 使用 random_split 隨機切分\n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        dataset, [train_len, val_len, test_len], generator=torch.Generator()\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        # collate_fn=collate_with_indices,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        # collate_fn=collate_with_indices,\n",
    "        num_workers=0,\n",
    "    )\n",
    "\n",
    "    return (train_dataset, val_dataset, test_dataset), (\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d51fc1",
   "metadata": {},
   "source": [
    "# define Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2abcf0",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b524f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 雙層卷積模組：Conv + Tanh，重複兩次\n",
    "# ================================================================\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"\n",
    "    UNet 的基本模組：兩層卷積，每層後接 Tanh 激活\n",
    "    可選 BatchNorm，但預設關閉以維持 NCA 的穩定性\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_ch, out_ch, k_size=3, mid_ch=None, use_bn=False):\n",
    "        super().__init__()\n",
    "        if not mid_ch:\n",
    "            mid_ch = out_ch\n",
    "        layers = [nn.Conv2d(in_ch, mid_ch, kernel_size=k_size, padding=\"same\"), nn.Tanh()]\n",
    "        if use_bn:\n",
    "            layers.insert(1, nn.BatchNorm2d(mid_ch))\n",
    "        layers += [nn.Conv2d(mid_ch, out_ch, kernel_size=k_size, padding=\"same\"), nn.Tanh()]\n",
    "        if use_bn:\n",
    "            layers.insert(-1, nn.BatchNorm2d(out_ch))\n",
    "        self.double_conv = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# 主體：UNet 版本的 Cellular Automata Model\n",
    "# ================================================================\n",
    "class CAModel(nn.Module):\n",
    "    \"\"\"\n",
    "    以 UNet 結構取代 rule_block 的 NCA 模型版本\n",
    "    功能：維持原本的 perception filters + UNet encoder-decoder 規則生成\n",
    "    config 需包含：\n",
    "      - config[\"model\"][\"channels\"]\n",
    "      - config[\"model\"][\"hidden_dim\"]\n",
    "      - config[\"model\"][\"kernel_count\"]\n",
    "      - config[\"model\"][\"unet_depth\"]\n",
    "      - config[\"model\"][\"base_channels\"]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.channel_n = config[\"model\"][\"channels\"]\n",
    "        self.hidden_dim = config[\"model\"].get(\"hidden_dim\", 128)\n",
    "        self.kernel_count = config[\"model\"].get(\"kernel_count\", 5)\n",
    "        self.unet_depth = config[\"model\"].get(\"unet_depth\", 3)  # 下採樣層數\n",
    "        self.base_ch = config[\"model\"].get(\"base_channels\", 16)\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # 感知濾波器初始化 (identity, sobel, laplacian, lbm)\n",
    "        # ------------------------------------------------------------\n",
    "        ident = torch.tensor([[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 0.0]])\n",
    "        sobel_x = torch.tensor([[-1.0, 0.0, 1.0], [-2.0, 0.0, 2.0], [-1.0, 0.0, 1.0]])\n",
    "        lap = torch.tensor([[1.0, 2.0, 1.0], [2.0, -12.0, 2.0], [1.0, 2.0, 1.0]])\n",
    "        lbm = torch.tensor(\n",
    "            [[1 / 36, 1 / 9, 1 / 36], [1 / 9, 4 / 9, 1 / 9], [1 / 36, 1 / 9, 1 / 36]]\n",
    "        )\n",
    "        init_filters = torch.stack(\n",
    "            [ident, sobel_x, sobel_x.T, lap, lbm]\n",
    "        )  # [filter_n, Hf, Wf]\n",
    "        self.filters = nn.Parameter(init_filters)  # 設為可學習參數\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # 建立 UNet 模型\n",
    "        # 輸入通道數 = channel_n * kernel_count\n",
    "        # 輸出通道數 = channel_n\n",
    "        # ------------------------------------------------------------\n",
    "        in_ch = self.channel_n * self.kernel_count\n",
    "        out_ch = self.channel_n\n",
    "        self.unet = self.build_unet(\n",
    "            in_ch, out_ch, depth=self.unet_depth, base_ch=self.base_ch\n",
    "        )\n",
    "\n",
    "    # ================================================================\n",
    "    # 建立 UNet 子結構\n",
    "    # ================================================================\n",
    "    def build_unet(self, in_ch, out_ch, depth=3, base_ch=64):\n",
    "        \"\"\"\n",
    "        建立標準 UNet 結構：\n",
    "        encoder（下採樣） + bottleneck + decoder（上採樣 + skip connection）\n",
    "        \"\"\"\n",
    "        # 編碼器部分\n",
    "        encs = nn.ModuleList()\n",
    "        pools = nn.ModuleList()\n",
    "        ch = base_ch\n",
    "        encs.append(DoubleConv(in_ch, ch, k_size=3))\n",
    "        for d in range(1, depth):\n",
    "            encs.append(DoubleConv(ch, ch * 2, k_size=3))\n",
    "            pools.append(nn.MaxPool2d(2))\n",
    "            ch *= 2\n",
    "\n",
    "        # bottleneck\n",
    "        bottleneck = DoubleConv(ch, ch * 2, k_size=3)\n",
    "\n",
    "\n",
    "        # 解碼器部分\n",
    "        decs = nn.ModuleList()\n",
    "        ups = nn.ModuleList()\n",
    "        for d in range(depth):\n",
    "            ups.append(nn.ConvTranspose2d(ch * 2, ch, kernel_size=2, stride=2))\n",
    "            decs.append(DoubleConv(ch * 2, ch, k_size=3))\n",
    "            ch = ch // 2\n",
    "\n",
    "        final_conv = nn.Conv2d(base_ch, out_ch, kernel_size=1)\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # 封裝成 UNet 子模組\n",
    "        # ------------------------------------------------------------\n",
    "        class _UNet(nn.Module):\n",
    "            def __init__(self, encs, pools, bottleneck, ups, decs, final_conv):\n",
    "                super().__init__()\n",
    "                self.encs = encs\n",
    "                self.pools = pools\n",
    "                self.bottleneck = bottleneck\n",
    "                self.ups = ups\n",
    "                self.decs = decs\n",
    "                self.final_conv = final_conv\n",
    "\n",
    "            def forward(self, x):\n",
    "                skips = []\n",
    "                xi = x\n",
    "\n",
    "                # -----------------------\n",
    "                # Encoder：特徵抽取\n",
    "                # -----------------------\n",
    "                for i, enc in enumerate(self.encs):\n",
    "                    xi = enc(xi)\n",
    "                    skips.append(xi)\n",
    "                    if i < len(self.pools):\n",
    "                        xi = self.pools[i](xi)\n",
    "\n",
    "                # -----------------------\n",
    "                # Bottleneck：深層特徵\n",
    "                # -----------------------\n",
    "                xi = self.bottleneck(xi)\n",
    "\n",
    "                # -----------------------\n",
    "                # Decoder：特徵還原 + Skip connection\n",
    "                # -----------------------\n",
    "                for up, dec, skip in zip(self.ups, self.decs, reversed(skips[:-0])):\n",
    "                    print(\"decode\")\n",
    "                    xi = up(xi)\n",
    "                    xi = torch.cat([skip, xi], dim=1)\n",
    "                    xi = dec(xi)\n",
    "\n",
    "                # -----------------------\n",
    "                # 最終輸出：預測 Δx\n",
    "                # -----------------------\n",
    "                print(\"frinfrf\", xi.shape)\n",
    "                out = xi\n",
    "                # out = self.final_conv(xi)\n",
    "                return out\n",
    "\n",
    "        return _UNet(encs, pools, bottleneck, ups, decs, final_conv)\n",
    "\n",
    "    # ================================================================\n",
    "    # Depthwise 感知卷積：對每個 channel 使用多個 filter\n",
    "    # ================================================================\n",
    "    def perchannel_conv(self, x: torch.Tensor, filters: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        對每個 channel 做 depthwise convolution\n",
    "        x: [B, C, H, W]\n",
    "        filters: [filter_n, Hf, Wf]\n",
    "        輸出: [B, C * filter_n, H, W]\n",
    "        \"\"\"\n",
    "        b, ch, h, w = x.shape\n",
    "        device = x.device\n",
    "        filters = filters.to(device)\n",
    "        y = x.reshape(b * ch, 1, h, w)\n",
    "        y = F.pad(y, [1, 1, 1, 1], mode=\"circular\")  # 週期性邊界條件\n",
    "        y = F.conv2d(y, filters[:, None])  # 卷積每個濾波器\n",
    "        y = y.reshape(b, -1, h, w)\n",
    "        return y\n",
    "\n",
    "    # ================================================================\n",
    "    # 感知函式：整合 depthwise filters\n",
    "    # ================================================================\n",
    "    def perception(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.perchannel_conv(x, self.filters)\n",
    "        # return\n",
    "\n",
    "    # ================================================================\n",
    "    # 單步更新：forward_pass\n",
    "    # ================================================================\n",
    "    def forward_pass(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        執行單步 NCA 更新：\n",
    "        1. 感知周圍鄰域\n",
    "        2. UNet 推斷更新量 Δx\n",
    "        3. 使用 gating 控制更新比例\n",
    "        4. 保留前 6 個通道不變\n",
    "        \"\"\"\n",
    "        check_tensor_nan_inf(x, \"model\")\n",
    "        y = self.perception(x)\n",
    "        check_tensor_nan_inf(y, \"model2\")\n",
    "        dx = self.unet(y)\n",
    "        check_tensor_nan_inf(dx, \"model3\")\n",
    "\n",
    "        # 前 6 個通道保留\n",
    "        no_change = x[:, :6, :, :]\n",
    "\n",
    "        # 更新：以第 3 個 channel 作為更新權重（可改成 learnable gate）\n",
    "        updated = x + dx * x[:, 2:3, :, :]\n",
    "        check_tensor_nan_inf(updated, \"model4\")\n",
    "\n",
    "        # 合併輸出\n",
    "        return torch.cat([no_change, updated[:, 6:, :, :]], dim=1)\n",
    "\n",
    "    # ================================================================\n",
    "    # 多步迭代更新\n",
    "    # ================================================================\n",
    "    def forward(self, x: torch.Tensor, n_times: int = 1) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        進行 n_times 次更新迭代\n",
    "        \"\"\"\n",
    "        for _ in range(n_times):\n",
    "            x = self.forward_pass(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468c8d4a",
   "metadata": {},
   "source": [
    "## EarlyStop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1257,
   "id": "115d9e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    \"\"\"\n",
    "    Early stopping helper\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.patience = config[\"earlystop\"][\"patience\"]\n",
    "        self.min_delta = config[\"earlystop\"][\"delta\"]\n",
    "        self.counter = 0\n",
    "        self.best_loss = np.inf\n",
    "        self.early_stop = False\n",
    "\n",
    "    def step(self, loss):\n",
    "        if loss + self.min_delta < self.best_loss:\n",
    "            self.best_loss = loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        return self.early_stop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b3a45b",
   "metadata": {},
   "source": [
    "## epoch step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1258,
   "id": "da3ff0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_nth_hidden_channels(x: torch.Tensor, init_batch_count: int, channel_start: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    將輸入 x (B, C, H, W) 的最後 init_batch_count 個 batch，\n",
    "    從 channel_start+1 之後的所有 channel 清零。\n",
    "    回傳新的 tensor，不修改原始 x。\n",
    "    \"\"\"\n",
    "    x_new = x.clone()  # 複製一份以免修改原資料\n",
    "    x_new[-init_batch_count:, channel_start:, :, :] = 0\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52551dda",
   "metadata": {},
   "source": [
    "### train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b15ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 模擬資料\n",
    "B, C, H, W = 8, 12, 4, 4\n",
    "x_batch = torch.randn(B, C, H, W)\n",
    "\n",
    "hidden_channel_start = 2  # 例如前3是visible，後面是hidden\n",
    "x_batch_reset = reset_nth_hidden_channels(x_batch, 4, 3)\n",
    "\n",
    "\n",
    "def plot_batch_channels(\n",
    "    x: torch.Tensor,\n",
    "    channel_range: tuple = None,   # (start, end)，顯示通道範圍 [start, end)\n",
    "    title: str = \"x\"\n",
    "):\n",
    "    \"\"\"\n",
    "    視覺化 tensor (B, C, H, W)\n",
    "    - 每一列 (row) 代表一個 batch\n",
    "    - 每一欄 (col) 代表一個 channel\n",
    "    - 左側顯示 batch index\n",
    "    - 上方顯示 channel index\n",
    "    \"\"\"\n",
    "    B, C, H, W = x.shape\n",
    "\n",
    "    # 選定顯示通道範圍\n",
    "    if channel_range is not None:\n",
    "        start, end = channel_range\n",
    "        x = x[:, start:end, :, :]\n",
    "        C = end - start\n",
    "    else:\n",
    "        start = 0\n",
    "\n",
    "    # 建立子圖\n",
    "    fig, axes = plt.subplots(B, C, figsize=(C * 0.6, B * 0.8))\n",
    "\n",
    "    # 若只有一列或一行，確保 axes 是 2D 陣列\n",
    "    if B == 1:\n",
    "        axes = axes[None, :]\n",
    "    if C == 1:\n",
    "        axes = axes[:, None]\n",
    "\n",
    "    for i in range(B):\n",
    "        for j in range(C):\n",
    "            ax = axes[i, j]\n",
    "            ax.imshow(x[i, j].detach().cpu(), cmap=\"viridis\")\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "            # 第一行（上方）顯示 channel index\n",
    "            if i == 0:\n",
    "                ax.set_title(f\"Ch {start + j}\", fontsize=9, pad=6)\n",
    "            # 第一列（左側）顯示 batch index\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(f\"B{i}\", fontsize=9, rotation=0, labelpad=25, va=\"center\")\n",
    "\n",
    "    # 調整間距：row 小、col 大\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.2)\n",
    "    plt.suptitle(title, fontsize=12, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# plot_batch_channels(x_batch, channel_range=(0, 12), title=\"Before Reset\")\n",
    "# plot_batch_channels(x_batch_reset, channel_range=(0, 12), title=\"After Reset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1260,
   "id": "787091d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "\n",
    "\n",
    "def train_one_epoch(\n",
    "    config: dict,\n",
    "    epoch_idx: int,\n",
    "    model: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    loss_fn,\n",
    "    train_dataset,\n",
    "    train_loader: DataLoader,\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    執行一次訓練迴圈（single epoch），包含：\n",
    "    - 隨機多步 rollout 模擬\n",
    "    - 狀態池 (x_pool) 的動態更新\n",
    "    - 損失計算與反向傳播\n",
    "\n",
    "    ## Parameters\n",
    "    ----------\n",
    "    config : dict\n",
    "        全域設定字典，應包含：\n",
    "        ```\n",
    "        config[\"training\"][\"batch_size\"]\n",
    "        config[\"training\"][\"rollout_max\"]\n",
    "        config[\"training\"][\"total_epochs\"]\n",
    "        config[\"system\"][\"device\"]\n",
    "        ```\n",
    "    epoch_idx : int\n",
    "        目前的 epoch 索引（從 0 起算）\n",
    "    model : nn.Module\n",
    "        NCA / GNCA 模型，用於前向演化\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        優化器，用於更新模型參數\n",
    "    loss_fn : Callable\n",
    "        自定義損失函數，需回傳一個 dict (各 loss 組件)\n",
    "    train_dataset : NCA_Dataset\n",
    "        具有 x_pool / y_pool 的資料集，允許即時更新\n",
    "    train_loader : DataLoader\n",
    "        提供 batch 的資料載入器\n",
    "\n",
    "    ## Returns\n",
    "    ----------\n",
    "    result_dict : dict\n",
    "        包含以下項目：\n",
    "        - `loss_dict` : dict\n",
    "            各項 loss 組件（例如 mse、div、momentum 等）\n",
    "        - `batch_dict` : dict\n",
    "            包含最後一個 batch 的資料：\n",
    "            ```\n",
    "            {\n",
    "                \"batch_idx\": int,\n",
    "                \"Y\": torch.Tensor,     # 目標狀態\n",
    "                \"X0\": torch.Tensor,    # 輸入初始狀態\n",
    "                \"X1\": torch.Tensor,    # 模型更新後狀態\n",
    "                \"diff\": torch.Tensor,  # Y - X1\n",
    "            }\n",
    "            ```\n",
    "        - `rollout_steps` : int\n",
    "            當前 epoch 使用的演化步數\n",
    "        - `total_loss` : torch.Tensor\n",
    "            該 epoch 最後一個 batch 的總損失值\n",
    "    \"\"\"\n",
    "\n",
    "    # ======== 取出訓練設定 ========\n",
    "    device = config[\"system\"][\"device\"]\n",
    "    rollout_max = config[\"training\"][\"rollout_max\"]\n",
    "    total_epochs = config[\"training\"][\"total_epochs\"]\n",
    "    hidden_channel_start = len(config[\"channels\"][\"bc\"])+len(config[\"channels\"][\"ic\"])\n",
    "    batch_size = config[\"training\"][\"batch_size\"]\n",
    "\n",
    "    model.train()\n",
    "    loss_dict = None\n",
    "    batch_dict = None\n",
    "    total_loss = 0\n",
    "\n",
    "    # ======================================================\n",
    "    # 隨機挑一個 batch\n",
    "    # ======================================================\n",
    "    random_batch_idx = random.randint(0, len(train_loader) - 1)\n",
    "\n",
    "    for i, (indices, x_batch, y_batch) in enumerate(train_loader):\n",
    "        if i != random_batch_idx:\n",
    "            continue\n",
    "\n",
    "        x_batch_reset = reset_nth_hidden_channels(\n",
    "            x_batch, batch_size//3 , hidden_channel_start\n",
    "        )\n",
    "        # if i==0:\n",
    "            # plot_batch_channels(x_batch_reset, channel_range=(0, 13), title=\"After Reset\")\n",
    "        x_batch_reset, y_batch = x_batch_reset.to(device), y_batch.to(device)\n",
    "        # --------------------------------------------------------\n",
    "        # 隨機決定本 batch 的演化步數（可隨 epoch 漸進）\n",
    "        # --------------------------------------------------------\n",
    "        rollout_steps = get_rollout_times(\n",
    "            epoch_idx, max_epoch=total_epochs, max_n=rollout_max, scale=1\n",
    "        )\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # 模型前向演化 (rollout)\n",
    "        # --------------------------------------------------------\n",
    "        x_pred = model(x_batch_reset, n_times=rollout_steps)\n",
    "        check_tensor_nan_inf([x_pred], \"train step3\")\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # 更新 x_pool（維持狀態記憶）\n",
    "        # --------------------------------------------------------\n",
    "        train_dataset.dataset.update_x_pool(indices, x_pred)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # 計算 loss\n",
    "        # --------------------------------------------------------\n",
    "        check_tensor_nan_inf([x_pred, y_batch], \"train step5\")\n",
    "        loss_dict = loss_fn(config, x_pred, y_batch, x_batch_reset)\n",
    "        check_tensor_nan_inf([loss_dict], \"train step6\")\n",
    "        total_loss = sum(loss_dict.values())\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # 反向傳播與梯度更新\n",
    "        # --------------------------------------------------------\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # 記錄最後一個 batch 結果\n",
    "        # --------------------------------------------------------\n",
    "        batch_dict = {\n",
    "            \"Y\": y_batch,\n",
    "            \"X0\": x_batch_reset,\n",
    "            \"X1\": x_pred,\n",
    "            \"diff\": y_batch - x_pred[:, : y_batch.shape[1]],\n",
    "        }\n",
    "\n",
    "    # hi()\n",
    "    # ======== 結構化回傳 ========\n",
    "    result_dict = {\n",
    "        \"loss_dict\": loss_dict,\n",
    "        \"batch_dict\": batch_dict,\n",
    "        \"total_loss\": total_loss,\n",
    "    }\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02daa72",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5430b6b",
   "metadata": {},
   "source": [
    "### eval step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1261,
   "id": "55cc8097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, Callable\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def evaluate_one_epoch(\n",
    "    config: dict,\n",
    "    epoch_idx: int,\n",
    "    model: torch.nn.Module,\n",
    "    loss_fn: Callable[[dict, torch.Tensor, torch.Tensor, torch.Tensor], Dict[str, torch.Tensor]],\n",
    "    val_dataset: NCA_Dataset,\n",
    "    val_loader: DataLoader,\n",
    "    metric_fn: Callable[[torch.Tensor, torch.Tensor], Dict[str, torch.Tensor]] = None,\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    執行單一 epoch 的驗證或測試流程，使用 DataLoader 批次化計算。\n",
    "    不會更新 x_pool 或執行反向傳播。\n",
    "\n",
    "    ## Parameters\n",
    "    ----------\n",
    "    config : dict  \n",
    "        模型與訓練設定，需包含：\n",
    "        ```\n",
    "        config[\"training\"][\"rollout_max\"]\n",
    "        config[\"system\"][\"device\"]\n",
    "        ```\n",
    "    epoch_idx : int  \n",
    "        當前 epoch 索引（從 0 起算）\n",
    "    model : nn.Module  \n",
    "        已訓練的模型，用於前向推論\n",
    "    loss_fn : Callable  \n",
    "        損失函數，回傳 dict (例如 {\"mse\": ..., \"momentum\": ...})\n",
    "    val_dataset : NCA_Dataset  \n",
    "        驗證資料集\n",
    "    val_loader : DataLoader  \n",
    "        驗證用的 DataLoader\n",
    "    metric_fn : Callable, optional  \n",
    "        額外的評估指標函式，例如 RMSE、SSIM 等。可為 None。\n",
    "\n",
    "    ## Returns\n",
    "    ----------\n",
    "    result_dict : dict  \n",
    "        - `avg_loss_dict` : 各項 loss 的平均值  \n",
    "        - `avg_metric_dict` : 各項 metric 的平均值  \n",
    "        - `batch_dict` : 最後一批樣本（X0, X1, Y, diff）  \n",
    "        - `rollout_steps` : int，使用的演化步數\n",
    "    \"\"\"\n",
    "\n",
    "    device = config[\"system\"][\"device\"]\n",
    "    rollout_steps = config[\"training\"][\"rollout_max\"]\n",
    "    model.eval()\n",
    "\n",
    "    loss_accumulator = {}\n",
    "    metric_accumulator = {}\n",
    "    loss_dict={}\n",
    "    num_batches = 0\n",
    "    total_loss=0\n",
    "    batch_dict = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # ======================================================\n",
    "        # 隨機挑一個 batch\n",
    "        # ======================================================\n",
    "        random_batch_idx = random.randint(0, len(val_loader) - 1)\n",
    "\n",
    "        for i, (indices, x_batch, y_batch) in enumerate(val_loader):\n",
    "            if i != random_batch_idx:\n",
    "                continue\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            # --------------------------------------------------------\n",
    "            # 前向推論（rollout）\n",
    "            # --------------------------------------------------------\n",
    "            x_pred = model(x_batch, n_times=rollout_steps)\n",
    "\n",
    "            # --------------------------------------------------------\n",
    "            # 計算 loss\n",
    "            # --------------------------------------------------------\n",
    "            loss_dict = loss_fn(config, x_pred, y_batch, x_batch)\n",
    "            total_loss  = sum(loss_dict.values())\n",
    "\n",
    "            # --------------------------------------------------------\n",
    "            # 計算 metric (optional)\n",
    "            # --------------------------------------------------------\n",
    "            if metric_fn is not None:\n",
    "                metric_dict = metric_fn(x_pred, y_batch)\n",
    "                for k, v in metric_dict.items():\n",
    "                    metric_accumulator[k] = metric_accumulator.get(k, 0.0) + v.detach().cpu().item()\n",
    "\n",
    "            num_batches += 1\n",
    "\n",
    "            # --------------------------------------------------------\n",
    "            # 記錄 batch 的資料\n",
    "            # --------------------------------------------------------\n",
    "            batch_dict = {\n",
    "                \"batch_idx\": indices,\n",
    "                \"Y\": y_batch,\n",
    "                \"X0\": x_batch,\n",
    "                \"X1\": x_pred,\n",
    "                \"diff\": y_batch - x_pred[:, :y_batch.shape[1]],\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "    # ======== 回傳統一結構 ========\n",
    "    result_dict = {\n",
    "        \"loss_dict\":loss_dict,\n",
    "        \"batch_dict\": batch_dict,\n",
    "        \"total_loss\":total_loss,\n",
    "    }\n",
    "\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e56351",
   "metadata": {},
   "source": [
    "## training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "id": "53588b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_checkpoint(model, optimizer, epoch, path):\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        },\n",
    "        path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "id": "9ebb442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "\n",
    "def run_training(\n",
    "    config: dict,\n",
    "    model: nn.Module,\n",
    "    optimizer: Optimizer,\n",
    "    loss_fn: Callable[[torch.Tensor, torch.Tensor], Dict[str, torch.Tensor]],\n",
    "    metric_fn: Callable[[torch.Tensor, torch.Tensor], Dict[str, torch.Tensor]] = None,\n",
    "    lr_sched: Optional[_LRScheduler] = None,\n",
    "    output_path: str = \"./output\",\n",
    ") -> None:\n",
    "\n",
    "    total_epochs = config[\"training\"][\"total_epochs\"]\n",
    "    save_interval = config[\"training\"][\"save_interval\"]\n",
    "\n",
    "    train_loss_log: list[float] = []\n",
    "    eval_loss_log: list[float] = []\n",
    "    eval_loss = 0\n",
    "    eval_metrics: List[np.ndarray] = []\n",
    "\n",
    "    early_stopper = EarlyStopper(config)\n",
    "    # =========================\n",
    "    # 讀取資料\n",
    "    npz_dict = np.load(config[\"dataset\"][\"dataset_npz_path\"])\n",
    "    # =========================\n",
    "    # init dataset 與 loader\n",
    "    multi_datasets, multi_dataloaders = init_dataset_and_loader(config, npz_dict)\n",
    "    (train_dataset, val_dataset, test_dataset) = multi_datasets\n",
    "    (train_loader, val_loader, test_loader) = multi_dataloaders\n",
    "\n",
    "    for epoch in trange(total_epochs, desc=\"Training Epochs\"):\n",
    "        # print(f\"epoch {epoch} start ------------------------------------\")\n",
    "        # ===== Training step =====\n",
    "        train_result_dict = train_one_epoch(\n",
    "            config, epoch, model, optimizer, loss_fn, train_dataset, train_loader\n",
    "        )\n",
    "        train_loss_dict = train_result_dict[\"loss_dict\"]\n",
    "        train_batch_dict = train_result_dict[\"batch_dict\"]\n",
    "        train_loss = train_result_dict[\"total_loss\"]\n",
    "\n",
    "        train_loss_log.append(train_loss.item())\n",
    "\n",
    "        if lr_sched is not None:\n",
    "            lr_sched.step()\n",
    "\n",
    "        # ===== Eval step =====\n",
    "        with torch.no_grad():\n",
    "\n",
    "            eval_result_dict = evaluate_one_epoch(\n",
    "                config,\n",
    "                epoch,\n",
    "                model,\n",
    "                loss_fn,\n",
    "                val_dataset,\n",
    "                val_loader,\n",
    "                metric_fn,\n",
    "            )\n",
    "            check_tensor_nan_inf(eval_result_dict, \"eval check3\")\n",
    "            eval_loss_dict = eval_result_dict[\"loss_dict\"]\n",
    "            eval_batch_dict = eval_result_dict[\"batch_dict\"]\n",
    "            eval_loss = eval_result_dict[\"total_loss\"]\n",
    "\n",
    "            eval_loss_log.append(eval_loss.item())\n",
    "\n",
    "        # ===== Visualization & Logging =====\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print_loss_dict(train_loss_dict, eval_loss_dict)\n",
    "            viz_loss(\n",
    "                train_loss_log, eval_loss_log, log_scale=True, window=total_epochs // 20\n",
    "            )\n",
    "            plt_acc_over_time(eval_metrics, title=\"L2 Metric\", ylabel=\"L2 Error\")\n",
    "            print(\"viz last batch in epoch\")\n",
    "            viz_batch_channels(train_batch_dict, show_channels=(0, 10))\n",
    "            viz_batch_samples(train_batch_dict, channel_start=6)\n",
    "            print(\"train x_pool\")\n",
    "            viz_pool(train_dataset.dataset.x_pool, epoch+1, show_all=False)\n",
    "            # print(\"train y_pool\")\n",
    "            # viz_pool(train_dataset.dataset.y_pool, epoch+1, show_all=False)\n",
    "\n",
    "            # viz_batch_channels(eval_batch_dict)\n",
    "\n",
    "        # ===== Checkpoint =====\n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            save_checkpoint(\n",
    "                model,\n",
    "                optimizer,\n",
    "                epoch + 1,\n",
    "                f\"{output_path}/checkpoint_epoch_{epoch+1}.pth\",\n",
    "            )\n",
    "\n",
    "        # ===== Early stopping =====\n",
    "        if early_stopper.step(train_loss) and epoch > 500:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "        # ---- Early stop if train loss is NaN ----\n",
    "        has_invalid = check_tensor_nan_inf([train_loss_dict, eval_loss_dict], \"loss_dict check\")\n",
    "        if has_invalid:\n",
    "            print_loss_dict(train_loss_dict, eval_loss_dict)\n",
    "            print(f\"NaN detected in train loss at epoch {epoch}, stopping training.\")\n",
    "            break\n",
    "\n",
    "        # ===== Memory cleanup 每個 epoch 強制釋放 =====\n",
    "        del (\n",
    "            train_loss_dict,\n",
    "            train_batch_dict,\n",
    "            eval_loss_dict,\n",
    "            eval_batch_dict,\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    # ===== Final save =====\n",
    "    try:\n",
    "        viz_loss(\n",
    "            train_loss_log,\n",
    "            eval_loss_log,\n",
    "            log_scale=True,\n",
    "            window=20,\n",
    "            save_path=f\"{output_path}/loss\",\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "    save_checkpoint(model, optimizer, total_epochs, f\"{output_path}/model_Final.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0ad3f3",
   "metadata": {},
   "source": [
    "我在做pi nca 的研究，以E4-5.1_UrbanTales_GNCA_overfit_dataNorm.ipynb為主，其餘輔助功能在\n",
    "\n",
    "C:\\Users\\GAI\\Desktop\\Scott\\NCA_Research\\E4_PI_NCA\\utils\n",
    "\n",
    "C:\\Users\\GAI\\Desktop\\Scott\\NCA_Research\\core_utils。\n",
    "\n",
    "輸出模型在:E4_PI_NCA\\outputs底下所有E4-5.1開頭的資料夾底下(小心gitignore)\n",
    "E4_PI_NCA\\outputs\\E4-5.1xx\\loss\\loss_epoch_xx.png\n",
    "E4_PI_NCA\\outputs\\E4-5.1\\E4-5.1xx\\loss\\loss_epoch_xx.png\n",
    "\n",
    "要求:\n",
    "1. 讀取所有context 並且分析為甚麼模型無法有效 overfir one sample\n",
    "2. 移除output底下所有訓練失敗的輸出(但是整理失敗原因)\n",
    "3. 對於所有output結果的loss and config參數設定 幫我分析總結\n",
    "\n",
    "\n",
    "- 所有輸出寫成簡潔乾淨的md檔案到\n",
    "\n",
    "C:\\Users\\GAI\\Desktop\\Scott\\NCA_Research\\E4_PI_NCA\\Discussion\\20251014_E4-5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1437a473",
   "metadata": {},
   "source": [
    "## metric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "id": "72f20a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_fn(\n",
    "    pred: torch.Tensor,\n",
    "    target: torch.Tensor,\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    計算多種 metric，包括 L1, L2, relative error。\n",
    "    預設只針對主要流體通道（風場相關）進行計算。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred : torch.Tensor\n",
    "        模型預測, shape = (B, C, H, W)\n",
    "    target : torch.Tensor\n",
    "        Ground truth, shape = (B, C, H, W)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        {\n",
    "            \"L1\": scalar,\n",
    "            \"L2\": scalar,\n",
    "            \"Relative\": scalar\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    # 假設通道結構為：\n",
    "    # ['coord_y', 'coord_x', 'geo_mask', 'topo',\n",
    "    #  'windInitX', 'windInitY', 'uped', 'vped', 'Uped', 'TKEped', 'Tuwped']\n",
    "\n",
    "    # 只取動態物理場（可根據需要調整）\n",
    "    # 例如風速分量 + turbulence 相關部分\n",
    "    field_channels = [4, 5, 6, 7, 8, 9, 10]  # 對應上方通道索引\n",
    "\n",
    "    pred_field = pred[:, field_channels, :, :]\n",
    "    target_field = target[:, field_channels, :, :]\n",
    "\n",
    "    eps = 1e-8\n",
    "    diff = pred_field - target_field\n",
    "\n",
    "    l1 = torch.mean(torch.abs(diff))\n",
    "    l2 = torch.mean(diff ** 2)\n",
    "    relative = torch.mean(torch.abs(diff) / (torch.abs(target_field) + eps))\n",
    "\n",
    "    return {\n",
    "        \"L1\": l1.detach().cpu(),\n",
    "        \"L2\": l2.detach().cpu(),\n",
    "        \"Relative\": relative.detach().cpu(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbad5f15",
   "metadata": {},
   "source": [
    "# main process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "id": "de6e8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"system\": {\n",
    "        \"device\": DEVICE,\n",
    "        \"output_path\": get_output_path(),\n",
    "        \"channel_names\": [\n",
    "            \"coord_y\",\n",
    "            \"coord_x\",\n",
    "            \"geo_mask\",\n",
    "            \"topo\",\n",
    "            \"windInitX\",\n",
    "            \"windInitY\",\n",
    "            \"uped\",\n",
    "            \"vped\",\n",
    "            \"Uped\",\n",
    "            \"TKEped\",\n",
    "            \"Tuwped\",\n",
    "        ],\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"dataset_npz_path\": \"../dataset/all_cases_BCHW.npz\",\n",
    "        \"train_ratio\" : 0.7,\n",
    "        \"val_ratio\"   : 0.2,\n",
    "        \"test_ratio\"  : 0.1,\n",
    "        \"dataset_size\": (64, 64),\n",
    "        \"pool_size\": 256,\n",
    "        \"img_size\": 64,\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"channels\": 20,\n",
    "        \"hidden_dim\": 256,\n",
    "        \"kernel_count\": 5,\n",
    "        \"num_hidden_layers\":2,\n",
    "        \"unet_depth\": 2,\n",
    "        \"base_channels\": 32,\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"total_epochs\": 2000,\n",
    "        \"batch_size\": 8,\n",
    "        \"epoch_item_repeat_num\": 2,\n",
    "        \"epoch_pool_size\": 1024 // 2,  # final_epoch_size/epoch_item_repeat_num\n",
    "        \"repeat_num_per_epoch\": 1,\n",
    "        \"rollout_min\": 1,\n",
    "        \"rollout_max\": 3,\n",
    "        \"save_interval\": 200,\n",
    "    },\n",
    "    \"earlystop\": {\n",
    "        \"patience\": 150,\n",
    "        \"delta\": 1e-4,\n",
    "    },\n",
    "    \"channels\": {\n",
    "        \"bc\": [0, 1, 2, 3],\n",
    "        \"ic\": [4, 5],\n",
    "    },\n",
    "    \"loss_weights\": {\n",
    "        \"phys\": [1.0, 2.0, 3.0],\n",
    "        # \"bc\": [1.0, 2.0, 3.0],\n",
    "        \"data\": [1.0, 2.0, 3.0],\n",
    "        \"uvel\": [1.0, 2.0, 3.0],\n",
    "        # \"iter\": [1.0, 2.0, 3.0],\n",
    "    },\n",
    "    \"optim\": {\"lr\": 1e-3},\n",
    "}\n",
    "\n",
    "\n",
    "OPTIONS_PATHS = [\n",
    "    # (\"model\", \"channels\"),\n",
    "    # (\"model\", \"num_hidden_layers\"),\n",
    "    # (\"training\", \"batch_size\"),\n",
    "    # (\"loss_weights\", \"phys\"),\n",
    "    # (\"loss_weights\", \"bc\"),\n",
    "    (\"loss_weights\", \"data\"),\n",
    "    (\"loss_weights\", \"uvel\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a4d8d2",
   "metadata": {},
   "source": [
    "## model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "id": "a9c300b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "=== CAModel Summary ===\n",
      "--------------------------------------------------\n",
      "Perception Filters:\n",
      "filters: shape=(5, 3, 3), requires_grad=True\n",
      "--------------------------------------------------\n",
      "[Perception] (8, 20, 64, 64) -> (8, 100, 64, 64)\n",
      "--------------------------------------------------\n",
      "UNet Forward:\n",
      "[Encoder 0]: (8, 100, 64, 64) -> (8, 32, 64, 64)\n",
      "[Pool 0]: (8, 32, 64, 64) -> (8, 32, 32, 32)\n",
      "[Encoder 1]: (8, 32, 32, 32) -> (8, 64, 32, 32)\n",
      "[Bottleneck]: (8, 64, 32, 32) -> (8, 128, 32, 32)\n",
      "\n",
      "ups ModuleList(\n",
      "  (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (1): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      ") \n",
      "decs ModuleList(\n",
      "  (0): DoubleConv(\n",
      "    (double_conv): Sequential(\n",
      "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      (1): Tanh()\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      (3): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (1): DoubleConv(\n",
      "    (double_conv): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      (1): Tanh()\n",
      "      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      (3): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "inside  xi_in torch.Size([8, 128, 32, 32])\n",
      "inside  xi torch.Size([8, 64, 64, 64])\n",
      "inside  skip torch.Size([8, 64, 32, 32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 32 but got size 64 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1266]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m dataset_size = cfg[\u001b[33m\"\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mdataset_size\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      7\u001b[39m batch_size = cfg[\u001b[33m\"\u001b[39m\u001b[33mtraining\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mcamodel_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_size\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_size\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1254]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mcamodel_summary\u001b[39m\u001b[34m(model, input_size, batch_size, device)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33minside  xi\u001b[39m\u001b[33m\"\u001b[39m,  xi.shape)\n\u001b[32m     62\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33minside  skip\u001b[39m\u001b[33m\"\u001b[39m,  skip.shape)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m xi = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33minside  xi\u001b[39m\u001b[33m\"\u001b[39m,  xi.shape)\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(dec)\n",
      "\u001b[31mRuntimeError\u001b[39m: Sizes of tensors must match except in dimension 1. Expected size 32 but got size 64 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "cfg = resolve_list_options(CONFIG, OPTIONS_PATHS)\n",
    "model = CAModel(cfg)\n",
    "\n",
    "channels = cfg[\"model\"][\"channels\"]\n",
    "kernel_count = cfg[\"model\"][\"kernel_count\"]\n",
    "dataset_size = cfg[\"dataset\"][\"dataset_size\"]\n",
    "batch_size = cfg[\"training\"][\"batch_size\"]\n",
    "\n",
    "camodel_summary(model, input_size=(channels, dataset_size[0], dataset_size[1]), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e4db92",
   "metadata": {},
   "source": [
    "# batch run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6db701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed empty folder: C:\\Users\\GAI\\Desktop\\Scott\\NCA_Research\\E4_PI_NCA\\outputs\\E4-6.1_PI-NCA_Unet_20251018-165634\n",
      "=== Perception Filters ===\n",
      "filters: shape=(5, 3, 3), requires_grad=True\n",
      "\n",
      "=== Rule Block Layers ===\n",
      "encs: ModuleList\n",
      "pools: ModuleList\n",
      "bottleneck: DoubleConv\n",
      "ups: ModuleList\n",
      "decs: ModuleList\n",
      "final_conv: Conv2d(in=64, out=20, kernel=(1, 1))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[43mhi\u001b[49m()\n\u001b[32m     31\u001b[39m optimizer = Optimizer.Adam(model.parameters(), lr=cfg[\u001b[33m\"\u001b[39m\u001b[33moptim\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'hi' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     log_file = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/training_error.log\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(log_file, \u001b[33m\"\u001b[39m\u001b[33ma\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m log_f:\n",
      "\u001b[31mNameError\u001b[39m: name 'model_path' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     62\u001b[39m     \u001b[38;5;66;03m# 釋放 GPU 記憶體\u001b[39;00m\n\u001b[32m     63\u001b[39m     \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m model\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43moptimizer\u001b[49m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m lr_sched\n\u001b[32m     67\u001b[39m     torch.cuda.empty_cache()\n",
      "\u001b[31mNameError\u001b[39m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import traceback\n",
    "import os\n",
    "import torch\n",
    "import gc  # Python garbage collector\n",
    "\n",
    "for run_id in range(50):\n",
    "    remove_empty_dirs(r\"C:\\Users\\GAI\\Desktop\\Scott\\NCA_Research\\E4_PI_NCA\")\n",
    "\n",
    "    try:\n",
    "        cfg = resolve_list_options(CONFIG, OPTIONS_PATHS)\n",
    "\n",
    "\n",
    "        # print(f\"Run {run_id}:\\n{cfg}\")\n",
    "        model = CAModel(cfg).to(DEVICE)\n",
    "        # 指定輸入尺寸: (channels, height, width)\n",
    "        in_channels = cfg[\"model\"][\"channels\"]\n",
    "        # summary(model, input_size=(in_channels, 64, 64))\n",
    "        print(\"=== Perception Filters ===\")\n",
    "        print(f\"filters: shape={tuple(model.filters.shape)}, requires_grad={model.filters.requires_grad}\")\n",
    "\n",
    "        print(\"\\n=== unet Layers ===\")\n",
    "        for name, layer in model.unet.named_children():\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                print(f\"{name}: Conv2d(in={layer.in_channels}, out={layer.out_channels}, kernel={layer.kernel_size})\")\n",
    "            else:\n",
    "                print(f\"{name}: {layer.__class__.__name__}\")\n",
    "\n",
    "\n",
    "        hi()\n",
    "        optimizer = Optimizer.Adam(model.parameters(), lr=cfg[\"optim\"][\"lr\"])\n",
    "        lr_sched = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.7)\n",
    "\n",
    "        model_path = get_output_path()\n",
    "\n",
    "        run_training(\n",
    "            cfg,\n",
    "            model,\n",
    "            optimizer,\n",
    "            loss_fn=pinn_loss,\n",
    "            metric_fn=metric_fn,\n",
    "            lr_sched=lr_sched,\n",
    "            output_path=model_path,\n",
    "        )\n",
    "\n",
    "        # 確保目錄存在再寫入\n",
    "        os.makedirs(model_path, exist_ok=True)\n",
    "        config_file_path = os.path.join(model_path, \"config.json\")\n",
    "        with open(config_file_path, \"w\") as f:\n",
    "            json.dump(cfg, f, indent=4)\n",
    "\n",
    "    except Exception as e:\n",
    "        log_file = f\"{model_path}/training_error.log\"\n",
    "        with open(log_file, \"a\") as log_f:\n",
    "            log_f.write(f\"Run {run_id} failed:\\n\")\n",
    "            log_f.write(traceback.format_exc())\n",
    "            log_f.write(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "        print(f\"Run {run_id} failed. See {log_file} for details.\")\n",
    "\n",
    "    finally:\n",
    "        # -----------------------------\n",
    "        # 釋放 GPU 記憶體\n",
    "        # -----------------------------\n",
    "        del model\n",
    "        del optimizer\n",
    "        del lr_sched\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # -----------------------------\n",
    "        # 釋放 Python 物件\n",
    "        # -----------------------------\n",
    "        gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a7ffdd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc5ad5da",
   "metadata": {},
   "source": [
    "# After training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a394116d",
   "metadata": {},
   "source": [
    "## viz pngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abed3a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "\n",
    "# def show_all_png(root_dir):\n",
    "#     png_files = []\n",
    "#     for dirpath, _, filenames in os.walk(root_dir):\n",
    "#         for f in filenames:\n",
    "#             if f.lower().endswith(\".png\") :\n",
    "#                 png_files.append(os.path.join(dirpath, f))\n",
    "\n",
    "#     if not png_files:\n",
    "#         print(\"No PNG files found.\")\n",
    "#         return\n",
    "\n",
    "#     for img_path in png_files:\n",
    "#         title = os.path.relpath(img_path, root_dir)\n",
    "#         if title.startswith(\"E4-5.1\"):\n",
    "#             print(f\"Showing {img_path}\")\n",
    "#             img = mpimg.imread(img_path)\n",
    "#             plt.imshow(img)\n",
    "#             plt.axis(\"off\")\n",
    "#             plt.title(title)  # 不顯示 root_dir 之前的路徑\n",
    "#             plt.show()\n",
    "\n",
    "# # 使用範例\n",
    "# show_all_png(r\"C:\\Users\\GAI\\Desktop\\Scott\\NCA_Research\\E4_PI_NCA\\outputs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dcfb6d",
   "metadata": {},
   "source": [
    "# test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5048cfab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_epoch_pool' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m os.makedirs(output_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# --- 初始化資料 ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m Y_batch = \u001b[43mcreate_epoch_pool\u001b[49m(mode=\u001b[33m\"\u001b[39m\u001b[33meval\u001b[39m\u001b[33m\"\u001b[39m).to(DEVICE)  \u001b[38;5;66;03m# [1, 32, 64, 64]\u001b[39;00m\n\u001b[32m     12\u001b[39m X_batch = init_X(Y_batch)  \u001b[38;5;66;03m# [batch, channel, H, W]\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 假設模型已經載入並設定 eval\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'create_epoch_pool' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "from PIL import Image  # 用來 resize\n",
    "\n",
    "output_dir = \"temp_frames\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- 初始化資料 ---\n",
    "Y_batch = create_epoch_pool(mode=\"eval\").to(DEVICE)  # [1, 32, 64, 64]\n",
    "X_batch = init_X(Y_batch)  # [batch, channel, H, W]\n",
    "\n",
    "# 假設模型已經載入並設定 eval\n",
    "load_model = CAModel(channel_n=CHANNELS).to(DEVICE)\n",
    "load_model.load_state_dict(torch.load(f\"{model_path}/model.pth\"))\n",
    "load_model.eval()\n",
    "\n",
    "rollout_steps = 50\n",
    "frames = []\n",
    "target_size = (1024, 1024)  # (W, H)\n",
    "\n",
    "for t in range(rollout_steps):\n",
    "    # 每步 rollout\n",
    "    X_batch = load_model(X_batch, n_times=1)\n",
    "\n",
    "    # 取第一個 batch 的前三個 channel作 RGB\n",
    "    x_np = X_batch[0, 4:7].detach().cpu().numpy()  # shape: [3, H, W]\n",
    "    frame = np.transpose(x_np, (1, 2, 0))         # shape: [H, W, 3]\n",
    "    frame = np.clip(frame, 0, 1)                  # 確保值在 0~1\n",
    "    frame_uint8 = (frame * 255).astype(np.uint8)\n",
    "\n",
    "    # resize\n",
    "    img = Image.fromarray(frame_uint8)\n",
    "    img = img.resize(target_size, resample=Image.BILINEAR)\n",
    "    frame_resized = np.array(img)\n",
    "\n",
    "    # 選擇是否存單張 PNG\n",
    "    frame_path = os.path.join(output_dir, f\"{t:03d}.png\")\n",
    "    imageio.imwrite(frame_path, frame_resized)\n",
    "\n",
    "    # 累積成影片幀\n",
    "    frames.append(frame_resized)\n",
    "\n",
    "# 儲存成 mp4\n",
    "video_path = f\"{model_path}/output.mp4\"\n",
    "imageio.mimsave(video_path, frames, fps=3)\n",
    "print(\"Saved mp4:\", video_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
