import numpy as np
import torch
from typing import Union, List, Tuple, Dict, Optional
from scipy.ndimage import generic_filter
import datetime
from pathlib import Path
import os
import inspect
import ipynbname
import matplotlib.pyplot as plt
from matplotlib import cm
import json
import random
import re


# ===========================================================================================
# region to_HWC
def to_HWC(arr: Union[np.ndarray, torch.Tensor]) -> Union[np.ndarray, torch.Tensor]:
    """
    å°‡è¼¸å…¥ 3D æˆ– 4D array / tensor è½‰æˆ channel-last æ ¼å¼ã€‚
    3D: (C, H, W) -> (H, W, C)
    4D: (B, C, H, W) -> (B, H, W, C)

    Parameters
    ----------
    arr : np.ndarray æˆ– torch.Tensor
        shape = (C,H,W) æˆ– (B,C,H,W)

    Returns
    -------
    np.ndarray æˆ– torch.Tensor
        channel-last array/tensorï¼Œèˆ‡è¼¸å…¥åŒé¡å‹
    """
    if isinstance(arr, np.ndarray):
        if arr.ndim == 3:
            return np.transpose(arr, (1, 2, 0))
        elif arr.ndim == 4:
            return np.transpose(arr, (0, 2, 3, 1))
        else:
            raise ValueError(f"è¼¸å…¥ np.ndarray ç¶­åº¦ {arr.ndim} ä¸æ”¯æ´, åªæ”¯æ´ 3D æˆ– 4D")
    elif isinstance(arr, torch.Tensor):
        if arr.ndim == 3:
            return arr.permute(1, 2, 0)
        elif arr.ndim == 4:
            return arr.permute(0, 2, 3, 1)
        else:
            raise ValueError(
                f"è¼¸å…¥ torch.Tensor ç¶­åº¦ {arr.ndim} ä¸æ”¯æ´, åªæ”¯æ´ 3D æˆ– 4D"
            )
    else:
        raise TypeError(
            f"è¼¸å…¥é¡å‹ {type(arr)} ä¸æ”¯æ´, åªæ”¯æ´ np.ndarray æˆ– torch.Tensor"
        )


# ===========================================================================================
# region print_dict_stats
def print_dict_stats(d: dict, prefix: str = ""):
    """
    éè¿´åˆ—å° dict tree çš„çµ±è¨ˆè³‡è¨Šã€‚

    Parameters
    ----------
    d : dict
        è¦åˆ—å°çš„å­—å…¸
    prefix : str
        ç”¨æ–¼éè¿´ç¸®æ’
    """
    for k, v in d.items():
        key_str = f"{prefix}{k}"
        if isinstance(v, dict):
            print(f"{key_str}: dict")
            print_dict_stats(v, prefix=prefix + "  ")
        elif isinstance(v, torch.Tensor):
            print(f"{key_str}: torch.Tensor, shape={tuple(v.shape)}, dtype={v.dtype}")
        elif isinstance(v, np.ndarray):
            print(f"{key_str}: np.ndarray, shape={v.shape}, dtype={v.dtype}")
        else:
            print(f"{key_str}: {type(v)}")


# ===========================================================================================
# region print_tensor_stats
def print_tensor_stats(
    x, name: str = "Tensor", max_C: int = None, as_plot: bool = False
) -> None:
    """
    è¼¸å‡º Tensor/Numpy channel-wise çµ±è¨ˆè³‡è¨Šï¼Œæ”¯æ´è¡¨æ ¼æˆ– boxplotã€‚

    Parameters
    ----------
    x : torch.Tensor | np.ndarray
        shape = (C,H,W) æˆ– (B,C,H,W)
    name : str
        è³‡æ–™åç¨±
    max_C : int, optional
        æœ€å¤šé¡¯ç¤ºå¤šå°‘å€‹ channel
    as_plot : bool, default=False
        True â†’ ç•« boxplot
        False â†’ å°å‡ºçµ±è¨ˆè¡¨
    """

    # ------------------------------------------------------------
    # å‹æ…‹çµ±ä¸€ï¼šè½‰æˆ numpy
    # ------------------------------------------------------------
    if isinstance(x, torch.Tensor):
        x = x.detach().cpu().numpy()
    elif not isinstance(x, np.ndarray):
        raise TypeError(f"{name} å¿…é ˆæ˜¯ torch.Tensor æˆ– np.ndarray")

    # ------------------------------------------------------------
    # æª¢æŸ¥ç¶­åº¦ä¸¦æ“·å– channel
    # ------------------------------------------------------------
    if x.ndim == 3:  # (C, H, W)
        C = x.shape[0]
        data = [x[c].flatten() for c in range(C)]
    elif x.ndim == 4:  # (B, C, H, W)
        B, C, H, W = x.shape
        data = [x[:, c, :, :].flatten() for c in range(C)]
    else:
        raise ValueError(f"{name} ç¶­åº¦éŒ¯èª¤ï¼šæœŸæœ› 3D æˆ– 4Dï¼Œä½†å¾—åˆ° ndim={x.ndim}")

    if max_C is not None:
        data = data[:max_C]

    # ------------------------------------------------------------
    # è¼¸å‡ºçµ±è¨ˆ
    # ------------------------------------------------------------
    if as_plot:
        # --- boxplot ---
        plt.figure(figsize=(min(len(data), 6), 3))
        plt.boxplot(data, labels=[f"ch{c}" for c in range(len(data))], showfliers=False)
        plt.title(f"{name} Channel-wise Distribution")
        plt.ylabel("Value")
        plt.xlabel("Channel")
        plt.grid(axis="y", linestyle="--", alpha=0.6)
        plt.tight_layout()
        plt.show()

    else:
        # --- è¡¨æ ¼è¼¸å‡º ---
        print(f"{name} Channel-wise stats (å…± {len(data)} å€‹ channel):")
        header = f"{'ch':<5} {'min':>10} {'q1':>10} {'mean':>10} {'q3':>10} {'max':>10}"
        print(header)
        print("-" * len(header))
        for i, arr in enumerate(data):
            q1, q3 = np.percentile(arr, [25, 75])
            print(
                f"{i:<5} {arr.min():>10.6f} {q1:>10.6f} {arr.mean():>10.6f} {q3:>10.6f} {arr.max():>10.6f}"
            )


# ===========================================================================================
# region split_cases
def split_cases(
    case_list: List[torch.Tensor],
    train_ratio: float = 0.7,
    eval_ratio: float = 0.2,
    test_ratio: float = 0.1,
    seed: int = 42,
) -> Tuple[List[torch.Tensor], List[torch.Tensor], List[torch.Tensor]]:
    """
    å°‡ä¸€å€‹ list of 3D tensors éš¨æ©Ÿåˆ†ç‚º train / eval / test ä¸‰å€‹é›†åˆã€‚

    åƒæ•¸
    ----------
    case_list : List[torch.Tensor]
        åŸå§‹è³‡æ–™ listï¼Œæ¯å€‹ tensor shape=(C, H, W)
    train_ratio : float
        è¨“ç·´é›†æ¯”ä¾‹
    eval_ratio : float
        é©—è­‰é›†æ¯”ä¾‹
    test_ratio : float
        æ¸¬è©¦é›†æ¯”ä¾‹
    seed : int
        éš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿å¯é‡ç¾

    å›å‚³
    ----------
    Tuple[List[torch.Tensor], List[torch.Tensor], List[torch.Tensor]]
        train_case_list, eval_case_list, test_case_list
    """
    if not np.isclose(train_ratio + eval_ratio + test_ratio, 1.0):
        raise ValueError("train_ratio + eval_ratio + test_ratio å¿…é ˆç­‰æ–¼ 1.0")

    np.random.seed(seed)
    indices = np.random.permutation(len(case_list))

    n = len(case_list)
    n_train = int(n * train_ratio)
    n_eval = int(n * eval_ratio)
    # å‰©ä¸‹çµ¦ test
    n_test = n - n_train - n_eval

    train_cases = [case_list[i] for i in indices[:n_train]]
    eval_cases = [case_list[i] for i in indices[n_train : n_train + n_eval]]
    test_cases = [case_list[i] for i in indices[n_train + n_eval :]]

    return train_cases, eval_cases, test_cases


# ===========================================================================================
# region get_output_path
def get_output_path(Suffix: str = None) -> str:
    """
    å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾ï¼ŒæœƒæŠ“å‘¼å«ç«¯çš„æª”æ¡ˆåç¨±
    """
    notebook_path = ipynbname.path()

    timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
    if Suffix:
        path = f"../outputs/{notebook_path.stem}_{timestamp}/{Suffix}"
    else:
        path = f"../outputs/{notebook_path.stem}_{timestamp}"

    output_path = Path(path)
    output_path.mkdir(parents=True, exist_ok=True)

    return str(output_path)


# ===========================================================================================
# region norm_CHW
def norm_CHW(arr: np.ndarray) -> np.ndarray:
    """
    å°æ¯å€‹ channel åš min-max normalization åˆ° [0,1]ã€‚
    è¼¸å…¥ arr å‡è¨­å·²ç¶“æ²’æœ‰ NaNã€‚
    """
    arr_norm = np.empty_like(arr, dtype=np.float32)
    for c in range(arr.shape[0]):
        ch = arr[c]
        min_val, max_val = ch.min(), ch.max()
        if max_val > min_val:
            arr_norm[c] = (ch - min_val) / (max_val - min_val)
        else:
            arr_norm[c] = ch * 0.0
    return arr_norm


# ===========================================================================================
# region norm_CHW_select
def norm_CHW_select(arr: np.ndarray, channels: list[int]) -> np.ndarray:
    """
    å°æŒ‡å®š channel åš min-max normalization åˆ° [0,1]ï¼Œå…¶ä»– channel ä¿æŒä¸è®Šã€‚

    Parameters
    ----------
    arr : np.ndarray
        shape = (C, H, W)
    channels : list[int]
        è¦æ­£è¦åŒ–çš„ channel index

    Returns
    -------
    np.ndarray
        shape = (C, H, W)
    """
    arr_norm = arr.copy().astype(np.float32)
    for c in channels:
        ch = arr[c]
        min_val, max_val = ch.min(), ch.max()
        if max_val > min_val:
            arr_norm[c] = (ch - min_val) / (max_val - min_val)
        else:
            arr_norm[c] = ch * 0.0
    return arr_norm


# ===========================================================================================
# region plot_HW3
def plot_HW3(hw3: Union[np.ndarray, torch.Tensor], show_axis: bool = False) -> None:
    """
    Plot a H x W x 3 RGB image (hw3), keeping x/y scale equal,
    optionally hiding axes.

    Parameters
    ----------
    hw3 : np.ndarray or torch.Tensor
        H x W x 3 RGB image with float values [0,1].
    show_axis : bool
        æ˜¯å¦é¡¯ç¤ºåº§æ¨™è»¸ã€‚
    """
    if isinstance(hw3, torch.Tensor):
        hw3 = hw3.detach().cpu().numpy()

    fig, ax = plt.subplots()
    ax.imshow(hw3, aspect="equal", origin="lower")

    if not show_axis:
        ax.axis("off")

    plt.show()


##---------------------------------------------------------------------------------------------------------------------------
# region channels_to_rgb
def channels_to_rgb(
    image: Union[np.ndarray, torch.Tensor], cmap: str = "jet"
) -> np.ndarray:
    """
    å°‡ H x W x C çš„å¤šé€šé“å½±åƒï¼Œæ¯å€‹ channel ç”¨ jet colormap æ˜ å°„æˆ RGBï¼Œ
    å›å‚³ B x H x W x 3ï¼Œå…¶ä¸­ B=Cã€‚

    Parameters
    ----------
    image : np.ndarray æˆ– torch.Tensor
        H x W x C å½±åƒ

    Returns
    -------
    bhw3 : np.ndarray
        B x H x W x 3 RGB æ˜ å°„å¾Œçµæœ
    """
    if isinstance(image, torch.Tensor):
        image = image.detach().cpu().numpy()

    # é™åˆ¶åƒç´ å€¼ç¯„åœ [0, 1]
    image = np.clip(image, 0.0, 1.0)

    H, W, C = image.shape
    bhw3 = np.zeros((C, H, W, 3), dtype=np.float32)

    cmap = cm.get_cmap(cmap)

    for i in range(C):
        channel = image[:, :, i]

        # å°‡ channel æ˜ å°„æˆ RGB [0,1]
        rgb = cmap(channel)[:, :, :3]
        bhw3[i] = rgb

    return bhw3


##---------------------------------------------------------------------------------------------------------------------------
# region print_loss_dict
def print_loss_dict(
    train_loss_dict: Optional[Dict[str, torch.Tensor]] = None,
    eval_loss_dict: Optional[Dict[str, torch.Tensor]] = None,
) -> None:
    """
    å®‰å…¨åˆ—å°è¨“ç·´èˆ‡é©—è­‰çš„ loss å€¼ (å°æ•¸é»å¾Œå››ä½)

    åƒæ•¸
    ----
    train_loss_dict : Optional[Dict[str, torch.Tensor]]
        è¨“ç·´éç¨‹ä¸­çš„ loss å­—å…¸ (key: loss åç¨±, value: loss tensor)
    eval_loss_dict : Optional[Dict[str, torch.Tensor]], default=None
        é©—è­‰éç¨‹ä¸­çš„ loss å­—å…¸ (è‹¥ç‚º None å‰‡ä¸è¼¸å‡º)

    å›å‚³
    ----
    None
    """

    def safe_print_dict(loss_dict, title: str):
        if not loss_dict:
            print(f"{title}: ç„¡å¯ç”¨è³‡æ–™ (None æˆ–ç©ºå­—å…¸)")
            return
        print(f"{title}:")
        for name, value in loss_dict.items():
            try:
                if value is None:
                    print(f"  {name}: None", end=" | ")
                elif isinstance(value, torch.Tensor):
                    print(f"  {name}: {value.item():.4f}", end=" | ")
                else:
                    print(f"  {name}: {float(value):.4f}", end=" | ")
            except Exception as e:
                print(f"  {name}: [ç„¡æ³•è§£æ: {type(value)}] ({e})", end=" | ")
        print("\n")

    print("\n========== Loss Summary ==========")
    safe_print_dict(train_loss_dict, "Train Losses")
    if eval_loss_dict is not None:
        safe_print_dict(eval_loss_dict, "Eval Losses")
    print("==================================\n")


##---------------------------------------------------------------------------------------------------------------------------
# region sort_pool_by_mse
def sort_pool_by_mse(
    X_pool: torch.Tensor,  # shape = (N, C, H, W)
    Y_pool: torch.Tensor,  # shape = (N, C, H, W)
    channel_start: int = 4,
    channel_end: int = 9,
) -> tuple[torch.Tensor, torch.Tensor]:
    """
    ç›´æ¥ä¾ X_pool èˆ‡ Y_pool çš„ MSE æ’åº (å°åˆ°å¤§)

    åƒæ•¸
    ----------
    X_pool : torch.Tensor
        è¼¸å…¥æ± , shape = (N, C, H, W)
    Y_pool : torch.Tensor
        ç›®æ¨™æ± , shape = (N, C, H, W)
    channel_start : int
        è¨ˆç®— MSE çš„èµ·å§‹ channel
    channel_end : int
        è¨ˆç®— MSE çš„çµæŸ channel (ä¸åŒ…å«)

    å›å‚³
    ----------
    X_sorted, Y_sorted : torch.Tensor
        ä¾ MSE æ’åºå¾Œçš„æ± 
    """
    # é¸å–æŒ‡å®š channel

    X_sel = X_pool[:, channel_start:channel_end, :, :]
    Y_sel = Y_pool[:, channel_start:channel_end, :, :]

    # è¨ˆç®—æ¯å€‹ sample çš„ MSE (å±•å¹³å¾Œå°æ¯å€‹ sample mean)
    N = X_sel.shape[0]
    mse_per_sample = ((X_sel - Y_sel) ** 2).view(N, -1).mean(dim=1)

    # ä¾ MSE æ’åº
    sorted_idx = torch.argsort(mse_per_sample)  # å°åˆ°å¤§

    X_sorted = X_pool[sorted_idx]
    Y_sorted = Y_pool[sorted_idx]

    return X_sorted, Y_sorted


##---------------------------------------------------------------------------------------------------------------------------
# region log_globals
def log_globals(
    scope: dict,
    log_dir: str = "train_log",
    log_file: str = "globals_log.txt",
    exclude_vars: list[str] = None,
) -> None:
    import os

    if exclude_vars is None:
        exclude_vars = ["TRAIN_CASES", "EVAL_CASES", "TEST_CASES", "F", "HTML"]

    os.makedirs(log_dir, exist_ok=True)
    log_path = os.path.join(log_dir, log_file)

    uppercase_vars = [
        name
        for name in scope
        if name.isupper() and name not in exclude_vars and not name.startswith("_")
    ]

    with open(log_path, "w", encoding="utf-8") as f:
        for name in uppercase_vars:
            value = scope[name]
            if hasattr(value, "shape"):
                f.write(f"{name}: shape = {value.shape}\n")
            else:
                f.write(f"{name} = {value}\n")

    print(f"å…¨åŸŸè®Šæ•¸å·²å¯«å…¥ {log_path}")


##---------------------------------------------------------------------------------------------------------------------------
# region check_tensor_nan_inf
import torch


def check_tensor_nan_inf(obj, name="tensor"):
    """
    æª¢æŸ¥ tensor æˆ–å·¢ç‹€çµæ§‹ä¸­æ˜¯å¦å«æœ‰ NaN / Infï¼Œä¸¦åˆ†é–‹è­¦å‘Š

    Parameters
    ----------
    obj : torch.Tensor, list, dict
        è¦æª¢æŸ¥çš„å°è±¡ï¼Œå¯ä»¥æ˜¯ tensor æˆ–å·¢ç‹€çµæ§‹
    name : str
        åç¨±ï¼Œç”¨æ–¼æ‰“å°æç¤º

    Returns
    -------
    has_invalid : bool
        True è¡¨ç¤ºæœ‰ NaN æˆ– Inf
    """
    has_invalid = False

    if isinstance(obj, torch.Tensor):
        if torch.isnan(obj).any():
            print(f"[Warning] {name} contains NaN")
            print("min:", obj.min().item())
            print("max:", obj.max().item())
            has_invalid = True
        if torch.isinf(obj).any():
            print(f"[Warning] {name} contains Inf")
            print("min:", obj.min().item())
            print("max:", obj.max().item())
            has_invalid = True

    elif isinstance(obj, dict):
        for k, v in obj.items():
            if check_tensor_nan_inf(v, f"{name}.{k}"):
                has_invalid = True

    elif isinstance(obj, (list, tuple)):
        for i, v in enumerate(obj):
            if check_tensor_nan_inf(v, f"{name}[{i}]"):
                has_invalid = True

    else:
        # é tensor çš„ç‰©ä»¶å¿½ç•¥
        pass

    return has_invalid


##---------------------------------------------------------------------------------------------------------------------------
# region minmax_scale_channelwise
def minmax_scale_channelwise(x):
    """
    å° BCHW æˆ– CHW çš„è³‡æ–™é€²è¡Œ channel-wise min-max normalizationï¼Œä½¿æ¯å€‹ channel éƒ½è½åœ¨ [0,1]ã€‚

    Args:
        x : torch.Tensor | np.ndarray
            shape = (C,H,W) æˆ– (B,C,H,W)

    Returns:
        åŒå‹æ…‹çš„ normalized array (å€¼åŸŸç‚º [0,1])
    """
    # ------------------------------------------------------------
    # çµ±ä¸€å‹æ…‹ â†’ numpy
    # ------------------------------------------------------------
    is_torch = isinstance(x, torch.Tensor)
    if is_torch:
        x = x.detach().cpu().numpy()
    elif not isinstance(x, np.ndarray):
        raise TypeError("è¼¸å…¥å¿…é ˆæ˜¯ torch.Tensor æˆ– np.ndarray")

    # ------------------------------------------------------------
    # æª¢æŸ¥ç¶­åº¦
    # ------------------------------------------------------------
    if x.ndim == 3:  # (C,H,W)
        x = x[None, ...]  # åŠ ä¸€å€‹ batch ç¶­åº¦ â†’ (1,C,H,W)
        squeeze_back = True
    elif x.ndim == 4:  # (B,C,H,W)
        squeeze_back = False
    else:
        raise ValueError(f"ä¸æ”¯æ´ ndim={x.ndim}, åªæ¥å— (C,H,W) æˆ– (B,C,H,W)")

    B, C, H, W = x.shape
    x_scaled = np.zeros_like(x, dtype=np.float32)

    # ------------------------------------------------------------
    # æ¯å€‹ channel ç¨ç«‹ç¸®æ”¾
    # ------------------------------------------------------------
    for c in range(C):
        ch_data = x[:, c, :, :]
        ch_min = np.nanmin(ch_data)
        ch_max = np.nanmax(ch_data)
        if np.isclose(ch_max, ch_min):
            # å¸¸æ•¸é€šé“ â†’ å…¨ç‚º 0
            x_scaled[:, c, :, :] = 0.0
        else:
            x_scaled[:, c, :, :] = (ch_data - ch_min) / (ch_max - ch_min)

    # ------------------------------------------------------------
    # ç§»é™¤ batch ç¶­åº¦ (è‹¥åŸæœ¬æ˜¯ CHW)
    # ------------------------------------------------------------
    if squeeze_back:
        x_scaled = x_scaled[0]

    # ------------------------------------------------------------
    # è‹¥åŸå§‹è¼¸å…¥æ˜¯ torch.Tensor â†’ è½‰å› torch
    # ------------------------------------------------------------
    if is_torch:
        x_scaled = torch.from_numpy(x_scaled)

    return x_scaled


##---------------------------------------------------------------------------------------------------------------------------
# region remove_empty_dirs
def remove_empty_dirs(root_dir: str) -> None:
    """
    éè¿´åˆªé™¤ root_dir ä¸‹çš„æ‰€æœ‰ç©ºè³‡æ–™å¤¾ (æ²’æœ‰æª”æ¡ˆï¼Œä¹Ÿæ²’æœ‰éç©ºå­è³‡æ–™å¤¾)

    Parameters
    ----------
    root_dir : str
        è¦æ¸…ç†çš„æ ¹ç›®éŒ„
    """
    for dirpath, dirnames, filenames in os.walk(root_dir, topdown=False):
        # å¦‚æœé€™å€‹è³‡æ–™å¤¾æ²’æœ‰æª”æ¡ˆï¼Œä¸”åº•ä¸‹å­è³‡æ–™å¤¾ä¹Ÿéƒ½è¢«åˆªå…‰
        if not dirnames and not filenames:
            try:
                os.rmdir(dirpath)
                print(f"Removed empty folder: {dirpath}")
            except OSError as e:
                print(f"Skip {dirpath}, error: {e}")


##---------------------------------------------------------------------------------------------------------------------------
# region timed
import time


def timed(func):
    """
    Decorator: è¨ˆç®—å‡½æ•¸åŸ·è¡Œæ™‚é–“
    """

    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        end = time.time()
        print(f"[TIMER] {func.__name__} åŸ·è¡Œæ™‚é–“: {end - start:.6f} ç§’")
        return result

    return wrapper


##---------------------------------------------------------------------------------------------------------------------------
# region get_rollout_times
def get_rollout_times(epoch, max_epoch, min_n=1, max_n=8, scale=1.0):
    """
    scale > 1 â†’ å¢é•·æ›´æ…¢
    """
    ratio = max_n / min_n
    n = min_n * (ratio ** (epoch / (scale * max_epoch)))
    return min(max_n, int(round(n)))


##---------------------------------------------------------------------------------------------------------------------------
# region view_npz
def view_npz(npz_path_or_obj):
    """
    æŸ¥çœ‹ npz æª”æ¡ˆå…§éƒ¨çµæ§‹èˆ‡æ¯å€‹ array çš„ shape / dtypeã€‚

    åƒæ•¸
    ----------
    npz_path_or_obj : str or np.lib.npyio.NpzFile
        npz æª”æ¡ˆè·¯å¾‘ï¼Œæˆ–å·²ç¶“ç”¨ np.load() æ‰“é–‹çš„ npz ç‰©ä»¶ã€‚
    """
    # å¦‚æœè¼¸å…¥æ˜¯è·¯å¾‘ï¼Œå…ˆ load
    if isinstance(npz_path_or_obj, str):
        data = np.load(npz_path_or_obj)
    else:
        data = npz_path_or_obj

    print("Keys in npz:", list(data.keys()))
    print("-" * 30)

    for key in data.keys():
        arr = data[key]
        print(f"Key: {key}")
        print(f"  Type: {type(arr)}")
        print(f"  Shape: {arr.shape}")
        print(f"  Dtype: {arr.dtype}")
        print("-" * 30)


##---------------------------------------------------------------------------------------------------------------------------
# region resolve_list_options
def resolve_list_options(config: dict, key_paths: list[tuple]) -> dict:
    new_config = json.loads(json.dumps(config))  # æ·±æ‹·è²ä¹¾æ·¨ç‰ˆæœ¬

    for path in key_paths:
        d = new_config
        for k in path[:-1]:
            d = d[k]
        last_key = path[-1]
        if isinstance(d.get(last_key), list):
            d[last_key] = random.choice(d[last_key])

    return new_config


##---------------------------------------------------------------------------------------------------------------------------
# region to_device
def to_device(data, device):
    if isinstance(data, torch.Tensor):
        return data.to(device)
    elif isinstance(data, dict):
        return {k: to_device(v, device) for k, v in data.items()}
    elif isinstance(data, list):
        return [to_device(v, device) for v in data]
    elif isinstance(data, tuple):
        return tuple(to_device(v, device) for v in data)
    else:
        return data  # é tensor åŸæ¨£è¿”å›


##---------------------------------------------------------------------------------------------------------------------------
# region cleanup_checkpoints
def cleanup_checkpoints(directory: str, pattern: str, keep_num: int = 3):
    """
    æ¸…ç†æŒ‡å®šç›®éŒ„ä¸‹çš„æ¨¡å‹æª¢æŸ¥é»æª”æ¡ˆï¼Œåªä¿ç•™æœ€æ–°çš„ N å€‹ã€‚

    Args:
        directory (str): æª¢æŸ¥é»æ‰€åœ¨çš„ç›®éŒ„è·¯å¾‘ã€‚
        pattern (str): æª¢æŸ¥é»æª”æ¡ˆåç¨±çš„æ­£è¦è¡¨é”å¼æ¨¡å¼ã€‚
                       (ä¾‹å¦‚: å¦‚æœæ‚¨çš„æª”åæ˜¯ 'ca_model_step_100.pth',
                       æ¨¡å¼å¯èƒ½åƒ 'ca_model_step_(\d+)\.pth')
        keep_num (int): æ¬²ä¿ç•™çš„æœ€æ–°æª¢æŸ¥é»æ•¸é‡ã€‚
    """

    # çµ„åˆå®Œæ•´çš„æ­£è¦è¡¨é”å¼æ¨¡å¼
    full_pattern = re.compile(pattern)

    # å„²å­˜ (æ­¥é©Ÿç·¨è™Ÿ, å®Œæ•´æª”æ¡ˆè·¯å¾‘) çš„åˆ—è¡¨
    found_checkpoints = []

    # éæ­·ç›®éŒ„ä¸­çš„æ‰€æœ‰æª”æ¡ˆ
    for filename in os.listdir(directory):
        match = full_pattern.match(filename)
        if match:
            # å‡è¨­ç¬¬ä¸€å€‹æ•ç²çµ„ (\d+) æ˜¯æ­¥æ•¸æˆ–é€±æœŸç·¨è™Ÿ
            step = int(match.group(1))
            file_path = os.path.join(directory, filename)
            found_checkpoints.append((step, file_path))

    # æ ¹æ“šæ­¥é©Ÿç·¨è™Ÿï¼ˆç¬¬ä¸€å€‹å…ƒç´ ï¼‰é€²è¡Œæ’åºï¼Œå¾èˆŠåˆ°æ–°
    found_checkpoints.sort(key=lambda x: x[0])

    # è¨ˆç®—éœ€è¦åˆªé™¤çš„èˆŠæª”æ¡ˆæ•¸é‡
    files_to_delete = len(found_checkpoints) - keep_num

    if files_to_delete > 0:
        # å–å¾—éœ€è¦åˆªé™¤çš„æª”æ¡ˆåˆ—è¡¨ (æœ€èˆŠçš„ files_to_delete å€‹)
        for _, path_to_delete in found_checkpoints[:files_to_delete]:
            os.remove(path_to_delete)
            print(f"âœ… å·²åˆªé™¤èˆŠæª¢æŸ¥é»ï¼š{path_to_delete}")

    if len(found_checkpoints) > keep_num:
        print(f"ğŸ—‘ï¸ ç›®å‰ä¿ç•™æœ€æ–°çš„ {keep_num} å€‹æª¢æŸ¥é»ã€‚")


##---------------------------------------------------------------------------------------------------------------------------
# region save_checkpoint
def save_checkpoint(
    model: torch.nn.Module,
    optimizer: torch.optim.Optimizer,
    epoch: int,
    path: str,
    cleanup_pattern: Optional[str] = "ca_model_step_(\d+)\.pth",
    keep_num: int = 3,
):
    """
    å„²å­˜æ¨¡å‹æª¢æŸ¥é»ï¼Œä¸¦å¯é¸åœ°æ¸…ç†èˆŠæª”æ¡ˆã€‚
    """
    # 1. å„²å­˜ç•¶å‰æª¢æŸ¥é»
    torch.save(
        {
            "epoch": epoch,
            "model_state_dict": model.state_dict(),
            "optimizer_state_dict": optimizer.state_dict(),
        },
        path,
    )
    print(f"ğŸ’¾ å·²å„²å­˜æ–°æª¢æŸ¥é»ï¼š{path}")

    # 2. æ¸…ç†èˆŠæª¢æŸ¥é»
    if cleanup_pattern:
        # å–å¾—å„²å­˜ç›®éŒ„
        directory = os.path.dirname(path)
        if not directory:  # å¦‚æœ path åªæ˜¯æª”åï¼Œå‡è¨­ç›®éŒ„æ˜¯ç•¶å‰ç›®éŒ„
            directory = "."

        cleanup_checkpoints(directory, cleanup_pattern, keep_num)
