我有一個想法 幫我做深入探討與細化研究構想脈絡
現在有很多視覺注意力的計算方式 比如用單個照片影片生成一個完整的注意力 gaze map
比如

- vas 3m 用單張照片生成 xy pixel attention heat map,
- SAL3D(一篇論文的 nn 方法)用 .xyz pointcloud 生成 pts 對應的 gaze (attention) value

但是建築領域的觀看者與被觀察物件的時序性有關(如何觀察，觀察順序，觀察時間，觀察角度)都會讓同一個物件(pt)產生不同的 attention value。

## 所以我想要限建立一個 nn 模型，達到不同的觀察角度生成不同的 attention point cloud。

- camera_pos_series :
  相機的空間姿態 與 視錐角度

- point_cloud:
  用照片建模方法把影片產生 xyz 點

## nn 模型

- 輸入: point_cloud and camera_pos_series
- 輸出: point_cloud 對應的 delta gaze value

## 訓練資料集

- ground truth gaze:
  利用實驗者帶一個 vr 紀錄相機姿態以及架設眼球追蹤裝置計算空間中一個點的注意時間
