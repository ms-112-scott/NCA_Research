{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a62e193",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "643cee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 標準庫\n",
    "import sys\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import glob\n",
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "\n",
    "# 2. 第三方套件\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tqdm\n",
    "from IPython.display import clear_output, display, HTML\n",
    "\n",
    "# 3. 影片相關\n",
    "\n",
    "# import cv2\n",
    "\n",
    "# 4. 設定 project 路徑（依你本機路徑調整）\n",
    "project_root = \"C:/Users/GAI/Desktop/Scott/NCA_Research\"\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# 5. IPython 魔法指令（Jupyter專用）\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# 6. 共享 core_utils 函式庫導入\n",
    "from core_utils.plotting import (\n",
    "    plt_HWC_split_channels,\n",
    "    plt_CFD_channels,\n",
    "    plt_random_cfd_slice\n",
    ")\n",
    "\n",
    "from core_utils.utils_io import (\n",
    "    np2pil,      # numpy → PIL Image\n",
    "    imwrite,     # 儲存圖像為檔案\n",
    "    imencode,    # 編碼圖像為 byte stream\n",
    "    im2url,      # 圖像轉 base64 URL（HTML 顯示用）\n",
    "    load_emoji,   # 載入 emoji 圖像\n",
    "    load_cfd_npy\n",
    ")\n",
    "\n",
    "# from core_utils.utils_image import (\n",
    "#     imshow,      # 在 notebook 顯示圖像\n",
    "#     tile2d,      # 多圖拼接\n",
    "#     zoom         # 放大圖像\n",
    "# )\n",
    "\n",
    "# from core_utils.utils_video import (\n",
    "#     save_video,  # 批次輸出影片\n",
    "#     VideoWriter  # 逐幀寫入影片（支援 context manager）\n",
    "# )\n",
    "\n",
    "# from core_utils.ops_tf_np import (\n",
    "#     to_rgb,\n",
    "#     to_rgba,\n",
    "#     to_alpha,\n",
    "#     crop_and_resize,\n",
    "#     get_random_cfd_slices,\n",
    "#     get_random_cfd_slices_pair\n",
    "# )\n",
    "\n",
    "\n",
    "# from core_utils.viz_train import (\n",
    "#     viz_pool,\n",
    "#     viz_batch,\n",
    "#     viz_loss\n",
    "# )\n",
    "\n",
    "\n",
    "# 6. 實驗項目 utils 函式庫導入\n",
    "from E1_basicGNCA.utils.SamplePool import SamplePool\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed3b83",
   "metadata": {},
   "source": [
    "## process urbantales cases into npz file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "323a2a05",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "found the following matches with the input file in xarray's IO backends: ['netcdf4', 'h5netcdf']. But their dependencies may not be installed, see:\nhttps://docs.xarray.dev/en/stable/user-guide/io.html \nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m case_name = ped_file.parent.name\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 讀取 NetCDF\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mxr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mped_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ds:\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# 將所有變數堆疊成 3D array (H, W, C)\u001b[39;00m\n\u001b[32m     14\u001b[39m     arrays = [ds[var].values \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m ds.data_vars]\n\u001b[32m     15\u001b[39m     ped_np = np.stack(arrays, axis=-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GAI\\miniconda3\\envs\\pytorch-py311\\Lib\\site-packages\\xarray\\backends\\api.py:741\u001b[39m, in \u001b[36mopen_dataset\u001b[39m\u001b[34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, create_default_indexes, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[39m\n\u001b[32m    738\u001b[39m     kwargs.update(backend_kwargs)\n\u001b[32m    740\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m     engine = \u001b[43mplugins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mguess_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m from_array_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    744\u001b[39m     from_array_kwargs = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GAI\\miniconda3\\envs\\pytorch-py311\\Lib\\site-packages\\xarray\\backends\\plugins.py:199\u001b[39m, in \u001b[36mguess_engine\u001b[39m\u001b[34m(store_spec)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    192\u001b[39m     error_msg = (\n\u001b[32m    193\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfound the following matches with the input file in xarray\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms IO \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    194\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbackends: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompatible_engines\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. But their dependencies may not be installed, see:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    195\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.xarray.dev/en/stable/user-guide/io.html \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    196\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    197\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n",
      "\u001b[31mValueError\u001b[39m: found the following matches with the input file in xarray's IO backends: ['netcdf4', 'h5netcdf']. But their dependencies may not be installed, see:\nhttps://docs.xarray.dev/en/stable/user-guide/io.html \nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html"
     ]
    }
   ],
   "source": [
    "\n",
    "# 資料夾路徑\n",
    "folder = Path(\"../dataset\")\n",
    "\n",
    "# 存放每個 case 最終 numpy array\n",
    "case_dict = {}\n",
    "\n",
    "# 遍歷所有 ped.nc 檔案\n",
    "for ped_file in folder.rglob(\"*ped.nc\"):\n",
    "    case_name = ped_file.parent.name\n",
    "    \n",
    "    # 讀取 NetCDF\n",
    "    with xr.open_dataset(ped_file) as ds:\n",
    "        # 將所有變數堆疊成 3D array (H, W, C)\n",
    "        arrays = [ds[var].values for var in ds.data_vars]\n",
    "        ped_np = np.stack(arrays, axis=-1)\n",
    "    \n",
    "    # 對應 topo 檔案\n",
    "    topo_file = ped_file.parent.glob(\"*_topo\")\n",
    "    topo_file = next(topo_file, None)\n",
    "    if topo_file:\n",
    "        topo = np.loadtxt(topo_file)[:, :, np.newaxis]  # (H, W, 1)\n",
    "        ped_np = np.concatenate([ped_np, topo], axis=2)  # 合併 (H, W, C+1)\n",
    "    \n",
    "    case_dict[case_name] = ped_np\n",
    "\n",
    "# =========================\n",
    "# 將整個 dict 存成 .npz 檔\n",
    "# =========================\n",
    "np.savez_compressed(\"../dataset/all_cases.npz\", **case_dict)\n",
    "\n",
    "print(\"所有 case 已存成 all_cases.npz\")\n",
    "print(\"範例 case shape:\", case_dict[next(iter(case_dict))].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a81de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"C:/Users/GAI/Desktop/Scott/NCA_Research/E4_PI-NCA/dataset/FR-PA-V1_d00/FR-PA-V1_d00_topo\"\n",
    "\n",
    "# # ===============================\n",
    "# # 讀取 topo 檔案\n",
    "# # ===============================\n",
    "# topo = np.loadtxt(path)   # shape (576, 576)\n",
    "# print(\"Topography shape:\", topo.shape)\n",
    "\n",
    "# # ===============================\n",
    "# # 2D 視覺化\n",
    "# # ===============================\n",
    "# plt.figure(figsize=(7,6))\n",
    "# plt.imshow(topo, origin='lower', cmap='terrain')\n",
    "# plt.colorbar(label=\"Height [m]\")\n",
    "# plt.title(\"Urban Topography (2D View)\")\n",
    "# plt.xlabel(\"X grid\")\n",
    "# plt.ylabel(\"Y grid\")\n",
    "# plt.show()\n",
    "\n",
    "# # ===============================\n",
    "# # 3D 視覺化 (保持比例)\n",
    "# # ===============================\n",
    "# ny, nx = topo.shape\n",
    "# X, Y = np.meshgrid(np.arange(nx), np.arange(ny))\n",
    "# fig = plt.figure(figsize=(10,8))\n",
    "# ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# surf = ax.plot_surface(X, Y, topo, cmap=\"terrain\", rstride=2, cstride=2,\n",
    "#                        linewidth=0, antialiased=True, alpha=1.0)\n",
    "\n",
    "# ax.set_xlabel(\"X grid\")\n",
    "# ax.set_ylabel(\"Y grid\")\n",
    "# ax.set_zlabel(\"Height [m]\")\n",
    "# ax.set_title(\"Urban Topography (3D Surface, Equal Aspect)\")\n",
    "\n",
    "# # 🔑 設定 xyz 軸等比例\n",
    "# max_range = np.array([X.max()-X.min(), Y.max()-Y.min(), topo.max()-topo.min()]).max()\n",
    "# x_mid = (X.max()+X.min()) * 0.5\n",
    "# y_mid = (Y.max()+Y.min()) * 0.5\n",
    "# z_mid = (topo.max()+topo.min()) * 0.5\n",
    "\n",
    "# ax.set_box_aspect([X.max()-X.min(), Y.max()-Y.min(), topo.max()-topo.min()])  # 等比例\n",
    "\n",
    "# fig.colorbar(surf, shrink=0.5, aspect=10, label=\"Height [m]\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pool(\n",
    "    case_dict: Dict[str, np.ndarray],\n",
    "    poolsize: int,\n",
    "    hw_size: int = 126\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    從 case_dict 隨機生成一個 pool，每個樣本為隨機裁剪的 (hw_size, hw_size, 6) 子區域。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    case_dict : Dict[str, np.ndarray]\n",
    "        key: case 名稱，value: numpy array，形狀 (H, W, C)\n",
    "    poolsize : int\n",
    "        pool 中樣本數量\n",
    "    hw_size : int, optional\n",
    "        每個樣本裁剪的高度與寬度, default=126\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        shape = (poolsize, hw_size, hw_size, 6)，每個樣本取前 6 個 channel\n",
    "    \"\"\"\n",
    "    pool = []\n",
    "    case_names = list(case_dict.keys())\n",
    "\n",
    "    for _ in range(poolsize):\n",
    "        # 隨機選擇一個 case\n",
    "        case_name = np.random.choice(case_names)\n",
    "        arr = case_dict[case_name]\n",
    "        \n",
    "        # 確保至少有 6 個 channel\n",
    "        if arr.shape[2] < 6:\n",
    "            raise ValueError(f\"{case_name} channel < 6\")\n",
    "        \n",
    "        H, W, _ = arr.shape\n",
    "        \n",
    "        # 隨機裁剪起始點\n",
    "        h_start = np.random.randint(0, H - hw_size + 1)\n",
    "        w_start = np.random.randint(0, W - hw_size + 1)\n",
    "        \n",
    "        # 裁剪子區域，只取前 6 個 channel\n",
    "        sub = arr[h_start:h_start+hw_size, w_start:w_start+hw_size, :6]\n",
    "        pool.append(sub)\n",
    "    \n",
    "    return np.stack(pool, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b17978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 讀取 .npz 檔\n",
    "# =========================\n",
    "dict_data = np.load(\"../dataset/all_cases.npz\", allow_pickle=True)\n",
    "\n",
    "pool = create_pool(dict_data, poolsize=64, hw_size=64)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
