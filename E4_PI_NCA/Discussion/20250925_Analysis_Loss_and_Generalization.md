# NCA 模型在 256x256 尺寸下 Loss 停滯與泛化性差的原因分析

**日期:** 2025年9月25日
**專案:** E4_PI_NCA
**問題:** NCA 模型在 64x64 尺寸的資料集上訓練效果良好，但在擴展到 256x256 尺寸並採用 Patch-Based 訓練時，出現 Loss 無法有效下降且泛化能力差的問題。

---

## 1. 核心問題：從局部規則到全局結構的尺度鴻溝

NCA 的核心思想是透過學習一套統一的 **局部規則**（細胞如何根據鄰域狀態更新自己），來湧現出期望的 **全局結構**。當目標圖像尺寸從 64x64 擴大到 256x256 時，狀態空間的複雜度增加了 16 倍，這道從局部到全局的鴻溝被急遽拉大，導致了以下幾個關鍵性的失敗點。

## 2. Loss 停滯的四大深層原因

### 2.1. Patch 上下文資訊不足 (The "Keyhole Problem")

- **問題描述**: 一個固定大小的 Patch（例如 64x64）在 256x256 的畫布上，其相對視野變得極小。這就像試圖透過鑰匙孔去理解整個房間的佈局。
- **深層影響**: 模型在單一 Patch 中永遠無法觀測到大於 Patch 尺寸的宏觀結構（例如，一個貫穿圖像的大型流體渦旋、建築物的完整輪廓）。因此，模型只能學習去擬合局部紋理或顏色塊，而無法理解這些局部特徵在全局中的空間關係和意義。它不知道自己是「身體」的一部分還是「背景」的一部分。

### 2.2. 樣本池劣化與污染 (Sample Pool Degradation)

- **問題描述**: NCA 的訓練依賴於一個不斷更新的樣本池（Sample Pool）。在 256x256 的巨大畫布上，訓練初期的隨機狀態距離目標狀態極其遙遠。
- **深層影響**:
    1.  **負向回饋循環**: 樣本池會迅速被大量無意義的、混亂的、高熵的「失敗樣本」所佔據。
    2.  **無效梯度**: 從這些壞樣本中採樣的 Patch 會產生大量無效或誤導性的梯度。模型被迫花費絕大部分精力去學習「如何消除混亂」，而不是「如何建構結構」。
    3.  **難以進入正軌**: 相較於 64x64 的小畫布，256x256 時模型偶然「猜對」並產生有用結構的機率大幅降低，導致訓練很難進入「從已有結構擴展」的良性循環。

### 2.3. 梯度的絕對局部性 (The Locality of Gradients)

- **問題描述**: 對單一 Patch 計算的 Loss，其產生的梯度只會更新 **該 Patch 內部** 的細胞。
- **深層影響**: 這個梯度對於 Patch 之外的細胞應該如何行動 **不提供任何資訊**。模型會陷入一種「局部擬合」的陷阱：它可能學會了完美地複製某個 Patch 的紋理，但這種局部最優解對於全局結構的形成可能是錯誤甚至有害的。例如，它可能在圖像中間生成了一塊屬於邊緣的紋理。

### 2.4. 超參數的尺度失配 (Hyperparameter Mismatch)

- **問題描述**: 在 64x64 驗證有效的超參數，在 16 倍複雜度的問題上幾乎必然失效。
- **深層影響**:
    - **模型容量**: 用於處理 4096 (64x64) 像素點的隱藏通道數和網絡深度，很可能不足以表達和處理 65536 (256x256) 像素點的複雜狀態。
    - **學習率**: 在一個更複雜、更崎嶇的 Loss Landscape 中，原有的學習率可能過大，導致梯度在峽谷兩側來回震盪而無法下降。

## 3. 泛化性差的原因分析

泛化性差是上述問題的直接後果。在 NCA 的語境下，「泛化性」指的是模型學到的是一套 **魯棒的、可重複的發育程式**，而不僅僅是記住了一張目標圖像。

- **過擬合於局部上下文**: 由於模型只能看到局部 Patch，它學到的規則變成了「如果我的鄰域是 A，我就變成 B」這種死板的對應關係，而不是「為了成為一個圓形，我這個位置的細胞應該這樣做」。
- **缺乏空間意識**: 模型沒有全局座標的概念，導致它學到的規則是平移不變的。它無法學習到位置相關的發育指令（例如，「在畫布中心生成一個種子，然後向外擴張」）。
- **對初始條件敏感**: 由於沒有學到魯棒的生長邏輯，只要初始種子或生長環境稍有不同，其發育過程就可能走向完全錯誤或崩潰的結果。

## 4. 結論

將 NCA 從小尺寸擴展到大尺寸，其失敗並非簡單的 Bug，而是一個根本性的挑戰：**必須為模型建立起從局部資訊到全局目標之間的橋樑**。

單純依賴 Patch-Based 的 MSE Loss，模型被困在了局部資訊的牢籠中。為了解決這個問題，必須引入能為模型提供全局上下文的機制，例如：

- **給予空間座標 (CoordConv)**
- **設計課程學習 (Curriculum Learning)**
- **改進採樣策略以引導學習方向**

只有這樣，模型才能學會真正的「發育程式」，而不是一個脆弱的「紋理複製器」。
